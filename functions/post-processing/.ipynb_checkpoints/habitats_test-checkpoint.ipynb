{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a38c59d8-b637-432a-bd33-43a6abec5df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "#pip install  rioxarray==0.3.1\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import cartopy.crs as ccrs\n",
    "import rasterio\n",
    "import os\n",
    "import matplotlib.colors\n",
    "scriptsdir = os.getcwd()\n",
    "from scipy.interpolate import griddata\n",
    "from functools import reduce\n",
    "import xarray\n",
    "import itertools\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cartopy.feature as cfeature\n",
    "import warnings\n",
    "from shapely.geometry import box\n",
    "import argparse\n",
    "\n",
    "\n",
    "\n",
    "models = [\"GAM\"]\n",
    "taxas = [\"Mammals\"]\n",
    "time= 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1d58030-71bf-4dca-be2c-92d1b4935420",
   "metadata": {},
   "outputs": [],
   "source": [
    "for taxa in taxas:   \n",
    "    for model in models:\n",
    "        convcodes = pd.read_csv(\"/storage/homefs/ch21o450/scripts/BioScenComb/data/IUCN_LUH_converion_table_Carlson.csv\")\n",
    "        dir_habclass = \"/storage/homefs/ch21o450/IUCN/Habitat_Classifications/\" + taxa + \"/\"\n",
    "        dir_species = \"/storage/workspaces/wa_climate/climate_trt/data/BioScen15/individual_projections/\" + taxa+ \"_\" + model +\"_results_climate/\"\n",
    "        available_file = os.listdir(dir_species)\n",
    "        available_file=available_file[:1]\n",
    "        available_names = [x.split(\".csv\")[0] for x in available_file]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408367ad-1199-4cd0-8ffc-adebe16718f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software.el7/software/Anaconda3/2021.11-foss-2021a/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3364: DtypeWarning: Columns (28,32) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "/software.el7/software/Anaconda3/2021.11-foss-2021a/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3364: DtypeWarning: Columns (27,32) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "/software.el7/software/Anaconda3/2021.11-foss-2021a/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3364: DtypeWarning: Columns (28,30) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "/software.el7/software/Anaconda3/2021.11-foss-2021a/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3364: DtypeWarning: Columns (27,31,87,91) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "years = ['1845', '1990', '1995', '2009', '2010', '2020', '2026', '2032', '2048', '2050', '2052', '2056', '2080', '2100', '2150', '2200', '2250']\n",
    "year_indices = {35: 9, 65: 12, 85: 13}\n",
    "selected_year = years[year_indices[time]]\n",
    "\n",
    "if time == 35 or time == 65:\n",
    "    GCMs = ['GFDL-ESM2M', 'IPSL-CM5A-LR', 'HadGEM2-ES', 'MIROC5']\n",
    "    bioscen_GCMs = ['GFDL.ESM2M', 'IPSL.CM5A-LR', 'HadGEM2.ES', 'MIROC5']\n",
    "    scenarios = [\"rcp26\", \"rcp60\"]\n",
    "    ssprcps_shorts = [\"ssp126\", \"ssp460\"]\n",
    "elif time == 85:\n",
    "    GCMs = ['IPSL-CM5A-LR', 'HadGEM2-ES', 'MIROC5']\n",
    "    bioscen_GCMs = ['IPSL.CM5A-LR', 'HadGEM2.ES', 'MIROC5']\n",
    "    scenarios = [\"rcp26\"]\n",
    "    ssprcps_shorts = [\"ssp126\"]\n",
    "\n",
    "category_mapping = {\n",
    "    'cropland': ['c3ann', 'c3per', 'c4ann', 'c4per', 'c3nfx'],\n",
    "    'pasture': ['pastr', 'range'],\n",
    "    'forest': ['primf', 'secdf'],\n",
    "    'natural_land': ['primn', 'secdn']\n",
    "}\n",
    "\n",
    "species_habitat_counts = {}\n",
    "category_dfs = {category: pd.DataFrame(columns=['Species']) for category in category_mapping}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_species_data(species_name, dir_species, dir_habclass, available_file, bioscen_GCM, scenario, model):\n",
    "    formatted_names = []\n",
    "\n",
    "    for species_name in available_names:\n",
    "        split_species_name = species_name.split(\"_\")[:2]\n",
    "        formatted_species_name = \" \".join(split_species_name)\n",
    "        formatted_names.append(formatted_species_name)\n",
    "\n",
    "    for i, species_name in enumerate(formatted_names):\n",
    "        formatted_species_name = species_name.replace(\" \", \"_\")\n",
    "        species_habitat_counts[formatted_species_name] = {f'LUH{i}': 0 for i in range(1,13)}\n",
    "\n",
    "\n",
    "        for file_name in available_file:\n",
    "            if formatted_species_name in file_name and model + '_dispersal.csv.xz' in file_name:\n",
    "                species_file = file_name\n",
    "                species_file2 = [x.split(\".csv\")[0] for x in species_file] \n",
    "                break\n",
    "        else:\n",
    "            bioscen_species = None\n",
    "            continue\n",
    "\n",
    "        bioscen_species = pd.read_csv(dir_species + file_name)\n",
    "\n",
    "        available_files_iucn = formatted_species_name + \".csv\"\n",
    "        if available_files_iucn in os.listdir(dir_habclass):\n",
    "            IUCN = pd.read_csv(dir_habclass + available_files_iucn)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    lon = bioscen_species[\"x\"]\n",
    "    lat = bioscen_species[\"y\"]\n",
    "    z = bioscen_species[bioscen_GCM + '_' + scenario + '_' + selected_year]\n",
    "\n",
    "    df = pd.DataFrame({\"lon\": lon, \"lat\": lat, \"vals\": z})\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    \n",
    "    convcodes_renamed = convcodes.rename(columns={'IUCN_hab':'result.code'})\n",
    "    IUCN['result.code'] = pd.to_numeric(IUCN['result.code'], errors='coerce')\n",
    "    Habitats = IUCN.merge(convcodes_renamed, left_on='result.code', right_on='result.code')\n",
    "\n",
    "    keys = ['LUH1', 'LUH2', 'LUH3', 'LUH4', 'LUH5', 'LUH6', 'LUH7', 'LUH8','LUH9','LUH10', 'LUH11', 'LUH12']\n",
    "    split_cols = Habitats['LUH'].str.split('.', expand=True)\n",
    "    for i, key in enumerate(keys):\n",
    "        if i < len(split_cols.columns):\n",
    "            Habitats[key] = split_cols[i]\n",
    "        else:\n",
    "            Habitats[key] = pd.Series(dtype='float64')\n",
    "    if len(Habitats.columns) > len(keys) + 1:\n",
    "        num_missing_cols = len(Habitats.columns) - len(keys) - 1\n",
    "        Habitats = Habitats.reindex(columns=list(Habitats.columns) + ['LUH{}'.format(i) for i in range(13, 13 + num_missing_cols)], fill_value=np.nan)\n",
    "    Habitats_suitable = Habitats[Habitats['result.suitability'] == 'Suitable'].copy()\n",
    "\n",
    "\n",
    "    for i in range(1, 13):  # Assuming you have up to LUH20\n",
    "        habitat_key = f'LUH{i}'\n",
    "\n",
    "        # Check if not all values are NaN\n",
    "        if not Habitats_suitable[habitat_key].isnull().all():\n",
    "            # Get the unique habitat classes in the column\n",
    "            habitats = Habitats_suitable[habitat_key].dropna().unique()\n",
    "\n",
    "            # Increment the count for each habitat class\n",
    "            for habitat in habitats:\n",
    "                if habitat not in species_habitat_counts[formatted_species_name]:\n",
    "                    species_habitat_counts[formatted_species_name][habitat] = 0\n",
    "                species_habitat_counts[formatted_species_name][habitat] += 1\n",
    "\n",
    "\n",
    "    category_counts = {}\n",
    "    species_counted = set()\n",
    "    # Iterate over each species' habitat counts\n",
    "    # Create a set to keep track of processed species\n",
    "    processed_species = set()\n",
    "\n",
    "    # Inside the loop where you categorize species and add them to dataframes\n",
    "    for species, counts in species_habitat_counts.items():\n",
    "        # Check if the species has already been processed\n",
    "        if species in processed_species:\n",
    "            continue\n",
    "\n",
    "        # Create a set to track unique categories for the current species\n",
    "        unique_categories = set()\n",
    "\n",
    "        # Iterate over each habitat count for the species\n",
    "        for habitat, count in counts.items():\n",
    "            # Check if the habitat belongs to any category in the mapping\n",
    "            for category, category_habitats in category_mapping.items():\n",
    "                if habitat in category_habitats:\n",
    "                    unique_categories.add(category)\n",
    "                    break  # Break once a match is found\n",
    "\n",
    "        # Iterate over the unique categories for the species\n",
    "        for category in unique_categories:\n",
    "            if not category_dfs[category]['Species'].str.contains(species).any():\n",
    "            # Add the species to the corresponding category dataframe\n",
    "                category_dfs[category] = category_dfs[category].append({'Species': species}, ignore_index=True)\n",
    "\n",
    "        # Add the processed species to the set\n",
    "        processed_species.add(species)\n",
    "\n",
    "def categorize_species():\n",
    "    species_counted = set()\n",
    "\n",
    "    for species, counts in species_habitat_counts.items():\n",
    "        if species in species_counted:\n",
    "            continue\n",
    "\n",
    "        unique_categories = {category for habitat, count in counts.items() for category, category_habitats in category_mapping.items() if habitat in category_habitats}\n",
    "        \n",
    "        for category in unique_categories:\n",
    "            category_dfs[category] = category_dfs[category].append({'Species': species}, ignore_index=True)\n",
    "\n",
    "        species_counted.add(species)\n",
    "\n",
    "# Main Loop\n",
    "for taxa in taxas:\n",
    "    convcodes = pd.read_csv(\"/storage/homefs/ch21o450/scripts/BioScenComb/data/IUCN_LUH_converion_table_Carlson.csv\")\n",
    "    dir_habclass = \"/storage/homefs/ch21o450/IUCN/Habitat_Classifications/\" + taxa + \"/\"\n",
    "    for model in models:\n",
    "        dir_species = \"/storage/workspaces/wa_climate/climate_trt/data/BioScen15/individual_projections/\" + taxa+ \"_\" + model + \"_results_climate/\"\n",
    "        available_file = os.listdir(dir_species)\n",
    "        available_names = [x.split(\".csv\")[0] for x in available_file]\n",
    "        for bioscen_GCM in bioscen_GCMs:\n",
    "            for scenario in scenarios:\n",
    "                for species_name in available_names[:1]:\n",
    "                    process_species_data(species_name, dir_species, dir_habclass, available_file, bioscen_GCM, scenario, model)\n",
    "\n",
    "categorize_species()\n",
    "\n",
    "df_forest = category_dfs['forest']\n",
    "df_pasture = category_dfs['pasture']\n",
    "df_cropland = category_dfs['cropland']\n",
    "df_natural_land = category_dfs['natural_land']\n",
    "\n",
    "# Print the dataframes\n",
    "print(\"Forest:\", df_forest)\n",
    "print(\"Pasture:\", df_pasture)\n",
    "print(\"Cropland:\", df_cropland)\n",
    "print(\"Natural Land:\", df_natural_land)\n",
    "\n",
    "df_nonforest = pd.DataFrame()\n",
    "df_nonforest = df_nonforest.append([df_pasture, df_cropland, df_natural_land], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d65ec9-64c6-4fec-973e-e92683139ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
