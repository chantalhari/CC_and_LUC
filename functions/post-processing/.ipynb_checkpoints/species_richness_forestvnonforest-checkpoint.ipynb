{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d64152dc-2d4d-4993-bcaf-5e391e507e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "#pip install  rioxarray==0.3.1\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import cartopy.crs as ccrs\n",
    "import rasterio\n",
    "import os\n",
    "import matplotlib.colors\n",
    "scriptsdir = os.getcwd()\n",
    "from scipy.interpolate import griddata\n",
    "from functools import reduce\n",
    "import xarray\n",
    "import itertools\n",
    "import argparse\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "545e0dc6-8dd9-4273-aafd-79caff7dcd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxas=[\"Mammals\",\"Amphibians\",\"Bird\"]\n",
    "models=[\"GAM\",\"GBM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d9197456-cc30-4f53-b7fd-2046205a9532",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_names =  {}\n",
    "for taxa in taxas:\n",
    "    for model in models:\n",
    "        dir_species = \"/storage/scratch/users/ch21o450/data/LandClim_Output/\" + model + \"/\" + taxa + \"/EWEMBI/\"\n",
    "        available_file = os.listdir(dir_species)\n",
    "        available_names = [x.split(\"_[1146].nc\")[0] for x in available_file]\n",
    "\n",
    "    species_names[taxa] = available_names[:10]\n",
    "    \n",
    "\n",
    "species_list= []\n",
    "species_list.append(species_names[taxa])\n",
    "# Load the df_forest and df_non_forest DataFrames\n",
    "df_forest = pd.read_csv('/storage/homefs/ch21o450/scripts/BioScenComb/habitat_counts/df_forest[35].csv')\n",
    "df_non_forest = pd.read_csv('/storage/homefs/ch21o450/scripts/BioScenComb/habitat_counts/df_non_forest[35].csv')\n",
    "\n",
    "# Create a dictionary to store the species category (forest or non-forest)\n",
    "species_category = {}\n",
    "\n",
    "# Iterate over the forest and non-forest categories\n",
    "for category, df in {'forest': df_forest, 'non_forest': df_non_forest}.items():\n",
    "    # Create a list to store species names based on the category\n",
    "    category_species = list(df['Species'])\n",
    "\n",
    "\n",
    "    model_names = ['GFDL-ESM2M', 'IPSL-CM5A-LR', 'HadGEM2-ES', 'MIROC5']\n",
    "    years = ['1845', '1990', '1995', '2009', '2010', '2020', '2026', '2032', '2048', '2050',\n",
    "             '2052', '2056', '2080', '2100', '2150', '2200', '2250']\n",
    "\n",
    "    for species_name in category_species:\n",
    "        # Check if the species is in the df_forest DataFrame\n",
    "        if species_name in df_forest['Species'].values:\n",
    "            species_category[species_name] = 'forest'\n",
    "        # Check if the species is in the df_non_forest DataFrame\n",
    "        elif species_name in df_non_forest['Species'].values:\n",
    "            species_category[species_name] = 'non_forest'\n",
    "\n",
    "\n",
    "    def newvalue_fun(time, model, netcdf_path_format, is_historical=False, scenario=None):\n",
    "        newvalue_dict = {model_name: {species_name: {} for species_name in category_species} for model_name in model_names}\n",
    "        sum_bin_dict = {model_name: {species_name: {} for species_name in category_species} for model_name in model_names}\n",
    "\n",
    "\n",
    "        for model_name in model_names:\n",
    "            for species_name in df_non_forest['Species']:\n",
    "                found = False\n",
    "                for taxa in taxas:\n",
    "                    try:\n",
    "                        if is_historical:\n",
    "                            ds = xr.open_dataset(netcdf_path_format.format(model, taxa, species_name, time), decode_times=False)\n",
    "                        else:\n",
    "                            ds = xr.open_dataset(netcdf_path_format.format(model, taxa, species_name, time, model_name, scenario), decode_times=False)\n",
    "                        found = True\n",
    "                        break  # Exit the loop if species is found in any taxa\n",
    "                    except:\n",
    "                        continue\n",
    "                if found:\n",
    "                    print(f\"Species {species_name} found in {taxa}.\")\n",
    "                    projections_dict = {}\n",
    "\n",
    "                    value_list = []\n",
    "                    for model_name in model_names:\n",
    "                        value_bin = newvalue_dict[model_name][species_name]\n",
    "                        value_list.append(value_bin)\n",
    "                        return value_list\n",
    "\n",
    "\n",
    "\n",
    "            for species_name in df_forest['Species']:\n",
    "                species_name_cleaned = species_name.strip()  # Remove leading and trailing spaces\n",
    "                found = False\n",
    "                for taxa in taxas:\n",
    "                    try:\n",
    "                        if is_historical:\n",
    "                            ds = xr.open_dataset(netcdf_path_format.format(model, taxa, species_name, time), decode_times=False)\n",
    "                        else:\n",
    "                            ds = xr.open_dataset(netcdf_path_format.format(model, taxa, species_name, time, model_name, scenario), decode_times=False)\n",
    "                        found = True\n",
    "                        break  # Exit the loop if species is found in any taxa\n",
    "                    except:\n",
    "                        continue\n",
    "                if found:\n",
    "                    newvalue = ds[\"newvalue\"]\n",
    "                    sum_bin = ds[\"sum_bin\"]\n",
    "\n",
    "                    newvalue_dict[model_name][species_name] = newvalue\n",
    "                    sum_bin_dict[model_name][species_name] = sum_bin\n",
    "                    print(f\"Species {species_name} found in {taxa}.\")\n",
    "                else:\n",
    "                    print(f\"Species {species_name} not found in any taxa\")\n",
    "                    projections_dict = {}\n",
    "                    for model_name in model_names:\n",
    "                        value_bin = newvalue_dict[model_name][species_name]\n",
    "                        value_list.append(value_bin)\n",
    "                        return value_list\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21cfbf3-2ace-47fa-9e6d-851ac60f54c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "689e0a79-aa05-4849-8c31-4447aa14bdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_names =  {}\n",
    "for taxa in taxas:\n",
    "    for model in models:\n",
    "        dir_species = \"/storage/scratch/users/ch21o450/data/LandClim_Output/\" + model + \"/\" + taxa + \"/EWEMBI/\"\n",
    "        available_file = os.listdir(dir_species)\n",
    "        available_names = [x.split(\"_[1146].nc\")[0] for x in available_file]\n",
    "\n",
    "    species_names[taxa] = available_names[:10]\n",
    "    \n",
    "\n",
    "species_list= []\n",
    "species_list.append(species_names[taxa])\n",
    "# Load the df_forest and df_non_forest DataFrames\n",
    "df_forest = pd.read_csv('/storage/homefs/ch21o450/scripts/BioScenComb/habitat_counts/df_forest[35].csv')\n",
    "df_non_forest = pd.read_csv('/storage/homefs/ch21o450/scripts/BioScenComb/habitat_counts/df_non_forest[35].csv')\n",
    "\n",
    "# Create a dictionary to store the species category (forest or non-forest)\n",
    "species_category = {}\n",
    "\n",
    "# Iterate over the forest and non-forest categories\n",
    "for category, df in {'forest': df_forest, 'non_forest': df_non_forest}.items():\n",
    "    # Create a list to store species names based on the category\n",
    "    category_species = list(df['Species'])\n",
    "\n",
    "\n",
    "    model_names = ['GFDL-ESM2M', 'IPSL-CM5A-LR', 'HadGEM2-ES', 'MIROC5']\n",
    "    years = ['1845', '1990', '1995', '2009', '2010', '2020', '2026', '2032', '2048', '2050',\n",
    "             '2052', '2056', '2080', '2100', '2150', '2200', '2250']\n",
    "\n",
    "    for species_name in category_species:\n",
    "        # Check if the species is in the df_forest DataFrame\n",
    "        if species_name in df_forest['Species'].values:\n",
    "            species_category[species_name] = 'forest'\n",
    "        # Check if the species is in the df_non_forest DataFrame\n",
    "        elif species_name in df_non_forest['Species'].values:\n",
    "            species_category[species_name] = 'non_forest'\n",
    "\n",
    "\n",
    "    def newvalue_fun(time, model, netcdf_path_format, is_historical=False, scenario=None):\n",
    "        newvalue_dict = {model_name: {species_name: {} for species_name in category_species} for model_name in model_names}\n",
    "        sum_bin_dict = {model_name: {species_name: {} for species_name in category_species} for model_name in model_names}\n",
    "\n",
    "\n",
    "        for model_name in model_names:\n",
    "            for species_name in df_non_forest['Species']:\n",
    "                found = False\n",
    "                for taxa in taxas:\n",
    "                    try:\n",
    "                        if is_historical:\n",
    "                            ds = xr.open_dataset(netcdf_path_format.format(model, taxa, species_name, time), decode_times=False)\n",
    "                        else:\n",
    "                            ds = xr.open_dataset(netcdf_path_format.format(model, taxa, species_name, time, model_name, scenario), decode_times=False)\n",
    "                        found = True\n",
    "                        break  # Exit the loop if species is found in any taxa\n",
    "                    except:\n",
    "                        continue\n",
    "                if found:\n",
    "                    print(f\"Species {species_name} found in {taxa}.\")\n",
    "                    projections_dict = {}\n",
    "\n",
    "                    value_list = []\n",
    "                    for model_name in model_names:\n",
    "                        value_bin = newvalue_dict[model_name][species_name]\n",
    "                        value_list.append(value_bin)\n",
    "                        value_bin_concat = xr.concat(value_list, dim=\"model_name\")\n",
    "                        mean_value_bin = value_bin_concat.mean(dim=\"model_name\")\n",
    "                        projections_dict[species_name] = mean_value_bin\n",
    "\n",
    "\n",
    "            for species_name in df_forest['Species']:\n",
    "                species_name_cleaned = species_name.strip()  # Remove leading and trailing spaces\n",
    "                found = False\n",
    "                for taxa in taxas:\n",
    "                    try:\n",
    "                        if is_historical:\n",
    "                            ds = xr.open_dataset(netcdf_path_format.format(model, taxa, species_name, time), decode_times=False)\n",
    "                        else:\n",
    "                            ds = xr.open_dataset(netcdf_path_format.format(model, taxa, species_name, time, model_name, scenario), decode_times=False)\n",
    "                        found = True\n",
    "                        break  # Exit the loop if species is found in any taxa\n",
    "                    except:\n",
    "                        continue\n",
    "                if found:\n",
    "                    newvalue = ds[\"newvalue\"]\n",
    "                    sum_bin = ds[\"sum_bin\"]\n",
    "\n",
    "                    newvalue_dict[model_name][species_name] = newvalue\n",
    "                    sum_bin_dict[model_name][species_name] = sum_bin\n",
    "                    print(f\"Species {species_name} found in {taxa}.\")\n",
    "                else:\n",
    "                    print(f\"Species {species_name} not found in any taxa\")\n",
    "                    projections_dict = {}\n",
    "                    for model_name in model_names:\n",
    "                        value_bin = newvalue_dict[model_name][species_name]\n",
    "                        value_list.append(value_bin)\n",
    "                        value_bin_concat = xr.concat(value_list, dim=\"model_name\")\n",
    "                        mean_value_bin = value_bin_concat.mean(dim=\"model_name\")\n",
    "                        projections_dict[species_name] = mean_value_bin\n",
    "\n",
    "\n",
    "        mean_value_bin = xr.concat(value_bin_list, dim=\"species\").sum(dim=\"species\")  # Ensemble mean over species\n",
    "        mean_value_bin = mean_value_bin.where(mean_value_bin > 0, 0)\n",
    "        return mean_value_bin\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def calculate_mean(time, model, netcdf_path_format, is_historical=False, scenario=None):\n",
    "        newvalue_dict = {model_name: {} for model_name in model_names}\n",
    "        sum_bin_dict = {model_name: {} for model_name in model_names}\n",
    "        lu_sum_bin_dict = {model_name: {} for model_name in model_names}\n",
    "\n",
    "        for model_name in model_names:\n",
    "            for name in category_species:\n",
    "                if is_historical:\n",
    "                    ds = xr.open_dataset(netcdf_path_format.format(model, taxa, name, time), decode_times=False)\n",
    "                else:\n",
    "                    ds = xr.open_dataset(netcdf_path_format.format(model, taxa, name, time, model_name, scenario), decode_times=False)\n",
    "                sum_bin = ds[\"sum_bin\"]\n",
    "\n",
    "                sum_bin_dict[model_name][species_name] = sum_bin\n",
    "                \n",
    "\n",
    "        projections_dict = {}\n",
    "\n",
    "        for name in cacategory_species:\n",
    "            sum_bin_list = []\n",
    "            for model_name in model_names:\n",
    "                sum_bin = sum_bin_dict[model_name][name]\n",
    "                sum_bin_list.append(sum_bin)\n",
    "            sum_bin_concat = xr.concat(sum_bin_list, dim=\"model_name\")\n",
    "            mean_sum_bin = sum_bin_concat.mean(dim=\"model_name\")\n",
    "            projections_dict[name] = mean_sum_bin\n",
    "\n",
    "        mean_sum_bin_list = list(projections_dict.values())\n",
    "        mean_sum_bin = xr.concat(mean_sum_bin_list, dim=\"species\").sum(dim=\"species\")  # Ensemble mean over species\n",
    "        mean_sum_bin = mean_sum_bin.where(mean_sum_bin > 0, 0)\n",
    "\n",
    "        return mean_sum_bin\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "33025d0e-0d35-41f2-90e2-580a12338ebe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'value_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/61712810/ipykernel_96055/386549649.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalue_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'value_list' is not defined"
     ]
    }
   ],
   "source": [
    "value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "06da3130-48c1-45a4-aca7-8372ee26fdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species Sorex_camtschatica found in Mammals.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate xarray Dataset and DataArray objects, got <class 'dict'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/61712810/ipykernel_96055/3303561241.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmean_value_bin_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewvalue_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistorical_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetcdf_path_format_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_historical\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/local/61712810/ipykernel_96055/55162206.py\u001b[0m in \u001b[0;36mnewvalue_fun\u001b[0;34m(time, model, netcdf_path_format, is_historical, scenario)\u001b[0m\n\u001b[1;32m     63\u001b[0m                         \u001b[0mvalue_bin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewvalue_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspecies_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                         \u001b[0mvalue_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_bin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                         \u001b[0mvalue_bin_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_name\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"species_name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                         \u001b[0mmean_value_bin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_bin_concat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"model_name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                         \u001b[0mprojections_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspecies_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_value_bin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/core/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    259\u001b[0m         )\n\u001b[1;32m    260\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m    262\u001b[0m             \u001b[0;34m\"can only concatenate xarray Dataset and DataArray \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;34mf\"objects, got {type(first_obj)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate xarray Dataset and DataArray objects, got <class 'dict'>"
     ]
    }
   ],
   "source": [
    "mean_value_bin_hist = newvalue_fun(historical_time, model, netcdf_path_format_hist, is_historical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "66013932-552e-44fa-8110-75b26b801b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mammals', 'Amphibians']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7e3c6b9b-1c3d-4040-a858-fe22e0c9ce54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species Sorex_camtschatica not found in any taxa\n",
      "Species Axis_porcinus not found in any taxa\n",
      "Species Phyllotis_amicus not found in any taxa\n",
      "Species Crinia_bilingua not found in any taxa\n",
      "Species Muscicapa_olivascens not found in any taxa\n",
      "Species Psittacula_krameri not found in any taxa\n",
      "Species Sorex_camtschatica not found in any taxa\n",
      "Species Axis_porcinus not found in any taxa\n",
      "Species Phyllotis_amicus not found in any taxa\n",
      "Species Crinia_bilingua not found in any taxa\n",
      "Species Muscicapa_olivascens not found in any taxa\n",
      "Species Psittacula_krameri not found in any taxa\n",
      "Species Sorex_camtschatica not found in any taxa\n",
      "Species Axis_porcinus not found in any taxa\n",
      "Species Phyllotis_amicus not found in any taxa\n",
      "Species Crinia_bilingua not found in any taxa\n",
      "Species Muscicapa_olivascens not found in any taxa\n",
      "Species Psittacula_krameri not found in any taxa\n",
      "Species Sorex_camtschatica not found in any taxa\n",
      "Species Axis_porcinus not found in any taxa\n",
      "Species Phyllotis_amicus not found in any taxa\n",
      "Species Crinia_bilingua not found in any taxa\n",
      "Species Muscicapa_olivascens not found in any taxa\n",
      "Species Psittacula_krameri not found in any taxa\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Sorex_camtschatica'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/61712810/ipykernel_96055/1015341878.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmean_value_bin_future\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewvalue_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetcdf_path_format_future\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_historical\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscenario\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/local/61712810/ipykernel_96055/3241580025.py\u001b[0m in \u001b[0;36mnewvalue_fun\u001b[0;34m(time, model, netcdf_path_format, is_historical, scenario)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mvalue_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mvalue_bin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewvalue_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0mvalue_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_bin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mvalue_bin_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"model_name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Sorex_camtschatica'"
     ]
    }
   ],
   "source": [
    "mean_value_bin_future = newvalue_fun(future_time, model, netcdf_path_format_future, is_historical=False, scenario=scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fba1a5-5ad7-48e8-bb67-1781acb24e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ap = argparse.ArgumentParser()\n",
    "\n",
    "# collect the function arguments\n",
    "\n",
    "ap.add_argument('-m', '--model', type=str, help=\"model, string\", nargs=\"+\", required=True)\n",
    "ap.add_argument('-a', '--taxa', type=str, help=\"taxa, string\", nargs=\"+\", required=True)\n",
    "\n",
    "# parse the arguments to the args object\n",
    "args = ap.parse_args()\n",
    "\n",
    "# *************************************************\n",
    "# Get arguments\n",
    "# *************************************************\n",
    "print(args)\n",
    "\n",
    "models = args.model\n",
    "taxas = args.taxa\n",
    "print(taxas)\n",
    "\n",
    "model_names = ['GFDL-ESM2M', 'IPSL-CM5A-LR', 'HadGEM2-ES', 'MIROC5']\n",
    "years = ['1845', '1990', '1995', '2009', '2010', '2020', '2026', '2032', '2048', '2050',\n",
    "         '2052', '2056', '2080', '2100', '2150', '2200', '2250']\n",
    "\n",
    "for taxa in taxas:\n",
    "    for model in models:\n",
    "        dir_species = \"/storage/scratch/users/ch21o450/data/LandClim_Output/\" + model + \"/\" + taxa + \"/EWEMBI/\"\n",
    "        available_file = os.listdir(dir_species)\n",
    "        available_names = [x.split(\"_[1146].nc\")[0] for x in available_file]\n",
    "\n",
    "    species_names = available_names\n",
    "\n",
    "    def newvalue_fun(time, model, netcdf_path_format, is_historical=False, scenario=None):\n",
    "        newvalue_dict = {model_name: {} for model_name in model_names}\n",
    "        sum_bin_dict = {model_name: {} for model_name in model_names}\n",
    "\n",
    "        for model_name in model_names:\n",
    "            for species_name in species_names:\n",
    "                if is_historical:\n",
    "                    ds = xr.open_dataset(netcdf_path_format.format(model, taxa, species_name, time), decode_times=False)\n",
    "                else:\n",
    "                    ds = xr.open_dataset(netcdf_path_format.format(model, taxa, model_name, scenario, species_name, time), decode_times=False)\n",
    "\n",
    "                newvalue = ds[\"newvalue\"]\n",
    "                sum_bin = ds[\"sum_bin\"]\n",
    "\n",
    "                newvalue_dict[model_name][species_name] = newvalue\n",
    "                sum_bin_dict[model_name][species_name] = sum_bin\n",
    "\n",
    "        projections_dict = {}\n",
    "\n",
    "        for species_name in species_names:\n",
    "            value_list = []\n",
    "            for model_name in model_names:\n",
    "                value_bin = newvalue_dict[model_name][species_name]\n",
    "                #value_bin = value_bin.where(value_bin > 0, 1)\n",
    "                #value_bin = (value_bin > 0.00)\n",
    "\n",
    "                value_list.append(value_bin)\n",
    "            value_bin_concat = xr.concat(value_list, dim=\"model_name\")\n",
    "            mean_value_bin = value_bin_concat.mean(dim=\"model_name\")\n",
    "            projections_dict[species_name] = mean_value_bin\n",
    "\n",
    "        value_bin_list = list(projections_dict.values())\n",
    "        mean_value_bin = xr.concat(value_bin_list, dim=\"species\").sum(dim=\"species\")  # Ensemble mean over species\n",
    "        mean_value_bin = mean_value_bin.where(mean_value_bin > 0, 0)\n",
    "        return mean_value_bin\n",
    "\n",
    "    def calculate_mean(time, model, netcdf_path_format, is_historical=False, scenario=None):\n",
    "        newvalue_dict = {model_name: {} for model_name in model_names}\n",
    "        sum_bin_dict = {model_name: {} for model_name in model_names}\n",
    "        lu_sum_bin_dict = {model_name: {} for model_name in model_names}\n",
    "\n",
    "        for model_name in model_names:\n",
    "            for species_name in species_names:\n",
    "                if is_historical:\n",
    "                    ds = xr.open_dataset(netcdf_path_format.format(model, taxa, species_name, time), decode_times=False)\n",
    "                else:\n",
    "                    ds = xr.open_dataset(netcdf_path_format.format(model, taxa, model_name, scenario, species_name, time), decode_times=False)\n",
    "                sum_bin = ds[\"sum_bin\"]\n",
    "                #lu_sum_bin = ds[\"sum_lu_binary\"]\n",
    "                #sum_bin = (sum_bin > 0.00)\n",
    "\n",
    "                sum_bin_dict[model_name][species_name] = sum_bin\n",
    "                #lu_sum_bin_dict[model_name][species_name] = lu_sum_bin\n",
    "\n",
    "        projections_dict = {}\n",
    "\n",
    "        for species_name in species_names:\n",
    "            sum_bin_list = []\n",
    "            for model_name in model_names:\n",
    "                sum_bin = sum_bin_dict[model_name][species_name]\n",
    "                sum_bin_list.append(sum_bin)\n",
    "            sum_bin_concat = xr.concat(sum_bin_list, dim=\"model_name\")\n",
    "            mean_sum_bin = sum_bin_concat.mean(dim=\"model_name\")\n",
    "            projections_dict[species_name] = mean_sum_bin\n",
    "\n",
    "        mean_sum_bin_list = list(projections_dict.values())\n",
    "        mean_sum_bin = xr.concat(mean_sum_bin_list, dim=\"species\").sum(dim=\"species\")  # Ensemble mean over species\n",
    "        mean_sum_bin = mean_sum_bin.where(mean_sum_bin > 0, 0)\n",
    "\n",
    "        return mean_sum_bin\n",
    "\n",
    "    historical_time = 1146\n",
    "    future_times = [35, 65]\n",
    "    scenarios = [\"rcp26\"]\n",
    "\n",
    "    netcdf_path_format_future = \"/storage/scratch/users/ch21o450/data/LandClim_Output/{}/{}/{}/{}/{}_[{}].nc\"\n",
    "    netcdf_path_format_hist = \"/storage/scratch/users/ch21o450/data/LandClim_Output/{}/{}/EWEMBI/{}_[{}].nc\"\n",
    "\n",
    "    mean_value_bin_hist = newvalue_fun(historical_time, model, netcdf_path_format_hist, is_historical=True)\n",
    "    mean_sum_bin_hist = calculate_mean(historical_time, model, netcdf_path_format_hist, is_historical=True)\n",
    "\n",
    "    mean_sum_bin_hist = mean_sum_bin_hist.isel(time=0)\n",
    "\n",
    "    year_indices = {1146: '1995', 35: '2050', 65: '2080', 85: '2100'}\n",
    "\n",
    "    for future_time in future_times:\n",
    "        for scenario in scenarios:\n",
    "            if future_time == 35 or future_time == 65:\n",
    "                model_names = ['GFDL-ESM2M', 'IPSL-CM5A-LR', 'HadGEM2-ES', 'MIROC5']\n",
    "            elif future_time == 85:\n",
    "                model_names = ['IPSL-CM5A-LR', 'HadGEM2-ES', 'MIROC5']\n",
    "\n",
    "            filename = f\"/storage/homefs/ch21o450/scripts/BioScenComb/intermediate_results/{taxa}_{model}_{historical_time}_{scenario}_species_count_per_SCDM_00th_mean_value_bin_future.nc\"\n",
    "            mean_value_bin_hist.to_netcdf(filename)\n",
    "\n",
    "            filename2 = f\"/storage/homefs/ch21o450/scripts/BioScenComb/intermediate_results/{taxa}_{model}_{historical_time}_{scenario}_species_count_per_SCDM_00th_mean_sum_bin_future.nc\"\n",
    "            mean_sum_bin_hist.to_netcdf(filename2)\n",
    "\n",
    "            mean_value_bin_future = newvalue_fun(future_time, model, netcdf_path_format_future, is_historical=False, scenario=scenario)\n",
    "            mean_sum_bin_future = calculate_mean(future_time, model, netcdf_path_format_future, is_historical=False, scenario=scenario)\n",
    "            mean_sum_bin_future = mean_sum_bin_future.isel(time=0)\n",
    "\n",
    "            filename = f\"/storage/homefs/ch21o450/scripts/BioScenComb/intermediate_results/{taxa}_{model}_{future_time}_{scenario}_species_count_per_SCDM_00th_mean_value_bin_future.nc\"\n",
    "            mean_value_bin_future.to_netcdf(filename)\n",
    "\n",
    "            filename2 = f\"/storage/homefs/ch21o450/scripts/BioScenComb/intermediate_results/{taxa}_{model}_{future_time}_{scenario}_species_count_per_SCDM_00th_mean_sum_bin_future.nc\"\n",
    "            mean_sum_bin_future.to_netcdf(filename2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
