{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1db0273a-5e1a-4a08-84cd-d2930eb6e6c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Basic Species Richness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b33683cd-f1e7-4755-a49c-60376197fd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BASCIC SPECIES RICHNESS\n",
    "#newvalue_future and _historical and sumbin_future and _historical\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "models = [\"GAM\", \"GBM\"]\n",
    "taxas = [\"Bird\", \"Mammals\", \"Amphibians\"]\n",
    "scenarios = [\"rcp26\", \"rcp60\"]\n",
    "historical_time = 1146\n",
    "future_time = 65\n",
    "\n",
    "year_indices = {1146: '1995', 35: '2050', 65: '2080', 85: '2100'}\n",
    "\n",
    "for time in [historical_time, future_time]:\n",
    "    for scenario in scenarios:\n",
    "        # Create empty arrays for storing the results for each taxa separately\n",
    "        diff_value_bin_combined_per_taxa = {}\n",
    "        diff_sum_bin_combined_per_taxa = {}\n",
    "        diff_combined_per_taxa = {}\n",
    "\n",
    "        for taxa in taxas:\n",
    "            diff_value_bin_combined_per_taxa[taxa] = np.zeros([360, 720])\n",
    "            diff_sum_bin_combined_per_taxa[taxa] = np.zeros([360, 720])\n",
    "            diff_combined_per_taxa[taxa] = np.zeros([360, 720])\n",
    "\n",
    "        # Initialize the combined arrays outside the taxa loop\n",
    "        diff_value_bin_combined = np.zeros([360, 720])\n",
    "        diff_sum_bin_combined = np.zeros([360, 720])\n",
    "        diff_combined = np.zeros([360, 720])\n",
    "\n",
    "        for row, taxa in enumerate(taxas):\n",
    "            # Reset the per model arrays for each taxa\n",
    "            diff_value_bin_models = []\n",
    "            diff_sum_bin_models = []\n",
    "            diff_models = []\n",
    "            percent_changes = []\n",
    "\n",
    "            for model in models:\n",
    "                newvalue_path = f\"/storage/scratch/users/ch21o450/data/SR/{taxa}_{model}_{time}_{scenario}_summedprobs_newvalue.nc\"\n",
    "                sumbin_path = f\"/storage/scratch/users/ch21o450/data/SR/{taxa}_{model}_{time}_{scenario}_summedprobs_sum.nc\"\n",
    "\n",
    "                mean_value_bin = xr.open_dataset(newvalue_path, decode_times=False).to_array().isel(variable=0)\n",
    "                mean_sum_bin = xr.open_dataset(sumbin_path, decode_times=False).to_array().isel(variable=0)\n",
    "\n",
    "                # Calculate the differences\n",
    "                diff_value_bin = mean_value_bin\n",
    "                diff_sum_bin = mean_sum_bin\n",
    "                diff = diff_sum_bin - diff_value_bin\n",
    "                change_percent = ((diff_sum_bin - diff_value_bin) / (diff_value_bin)) * 100\n",
    "                percent_changes.append(change_percent)\n",
    "\n",
    "                # append the differences to the model-specific lists\n",
    "                diff_value_bin_models.append(diff_value_bin)\n",
    "                diff_sum_bin_models.append(diff_sum_bin)\n",
    "                diff_models.append(diff)\n",
    "\n",
    "            # Calculate the ensemble mean outside of the innermost loop\n",
    "            diff_value_bin_ensemble = xr.concat(diff_value_bin_models, dim=\"ensemble\").mean(dim=\"ensemble\")\n",
    "            diff_sum_bin_ensemble = xr.concat(diff_sum_bin_models, dim=\"ensemble\").mean(dim=\"ensemble\")\n",
    "\n",
    "            diff_value_bin_ensemble = diff_value_bin_ensemble\n",
    "            diff_sum_bin_ensemble = diff_sum_bin_ensemble\n",
    "            diff_ensemble = diff_sum_bin_ensemble - diff_value_bin_ensemble\n",
    "\n",
    "            # Append the ensemble mean to the overall results for this taxa\n",
    "            diff_value_bin_combined_per_taxa[taxa] = diff_value_bin_ensemble\n",
    "            diff_sum_bin_combined_per_taxa[taxa] = diff_sum_bin_ensemble\n",
    "            diff_combined_per_taxa[taxa] = diff_ensemble\n",
    "\n",
    "        # Calculate the overall species richness sum over all taxa\n",
    "        diff_value_bin_combined = sum(diff_value_bin_combined_per_taxa.values())\n",
    "        diff_sum_bin_combined = sum(diff_sum_bin_combined_per_taxa.values())\n",
    "        diff_combined = sum(diff_combined_per_taxa.values())\n",
    "\n",
    "        diff_newvalue = diff_value_bin_combined\n",
    "        diff_sumbin = diff_sum_bin_combined\n",
    "        diff_combined = diff_combined\n",
    "\n",
    "        # Get rid of fine line at equator\n",
    "        land_sea_mask = xr.open_dataset(\"/storage/workspaces/wa_climate/climate_trt/chari/LUH2/remapped_luh2_ssp126.nc\", decode_times=False).primf\n",
    "        diff_newvalue_masked = diff_newvalue.where(land_sea_mask >= 0)\n",
    "        diff_newvalue = diff_newvalue_masked.isel(time=0)\n",
    "\n",
    "        output_path_diff_newvalue = f\"/storage/scratch/users/ch21o450/data/SRnew/SR_CC_{time}_{scenario}.nc\"\n",
    "        diff_newvalue.to_netcdf(output_path_diff_newvalue, format='NETCDF4')\n",
    "\n",
    "        # Write out diff_sumbin as netCDF\n",
    "        output_path_diff_sumbin = f\"/storage/scratch/users/ch21o450/data/SRnew/SR_CCLUC_{time}_{scenario}.nc\"\n",
    "        diff_sumbin.to_netcdf(output_path_diff_sumbin, format='NETCDF4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa4a3b0-b732-467a-8e3f-3e6f16e19b9b",
   "metadata": {},
   "source": [
    "per SDM and GCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b11ef19b-12c4-4fdc-a29c-d7076600b9cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: b'/storage/scratch/users/ch21o450/data/SR/Bird_GAM_GFDL-ESM2M_1146_rcp26_summedprobs_newvalue.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36m_acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                 \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/lru_cache.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('/storage/scratch/users/ch21o450/data/SR/Bird_GAM_GFDL-ESM2M_1146_rcp26_summedprobs_newvalue.nc',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), '7f4356d9-6c2d-47ec-a530-205d29541b01']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/1746954/ipykernel_12711/299975147.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0msumbin_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"/storage/scratch/users/ch21o450/data/SR/{taxa}_{model}_{model_name}_{time}_{scenario}_summedprobs_sum.nc\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                     \u001b[0mmean_value_bin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewvalue_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                     \u001b[0mmean_sum_bin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msumbin_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0moverwrite_encoded_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"overwrite_encoded_chunks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m     backend_ds = backend.open_dataset(\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0mdrop_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_variables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, lock, autoclose)\u001b[0m\n\u001b[1;32m    575\u001b[0m     ):\n\u001b[1;32m    576\u001b[0m         \u001b[0mfilename_or_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_normalize_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         store = NetCDF4DataStore.open(\n\u001b[0m\u001b[1;32m    578\u001b[0m             \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mnetCDF4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         )\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautoclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_remote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_remote_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen_store_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m_acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneeds_lock\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m             \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nc4_require_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software.el7/software/Anaconda3/2021.11-foss-2021a/lib/python3.9/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36macquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0macquire_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;34m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_acquire_with_cache_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneeds_lock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36m_acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                 \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                     \u001b[0;31m# ensure file doesn't get overridden when opened again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'/storage/scratch/users/ch21o450/data/SR/Bird_GAM_GFDL-ESM2M_1146_rcp26_summedprobs_newvalue.nc'"
     ]
    }
   ],
   "source": [
    "#BASCIC SPECIES RICHNESS\n",
    "#newvalue_future and _historical and sumbin_future and _historical\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "models = [\"GAM\", \"GBM\"]\n",
    "taxas = [\"Bird\", \"Mammals\", \"Amphibians\"]\n",
    "scenarios = [\"rcp26\", \"rcp60\"]\n",
    "historical_time = 1146\n",
    "future_time = 65\n",
    "\n",
    "model_names = ['GFDL-ESM2M', 'IPSL-CM5A-LR', 'HadGEM2-ES', 'MIROC5']\n",
    "\n",
    "year_indices = {1146: '1995', 35: '2050', 65: '2080', 85: '2100'}\n",
    "\n",
    "for time in [historical_time, future_time]:\n",
    "    for scenario in scenarios:\n",
    "        # Create empty arrays for storing the results for each taxa separately\n",
    "        diff_value_bin_combined_per_taxa = {}\n",
    "        diff_sum_bin_combined_per_taxa = {}\n",
    "        diff_combined_per_taxa = {}\n",
    "\n",
    "        for taxa in taxas:\n",
    "            diff_value_bin_combined_per_taxa[taxa] = np.zeros([360, 720])\n",
    "            diff_sum_bin_combined_per_taxa[taxa] = np.zeros([360, 720])\n",
    "            diff_combined_per_taxa[taxa] = np.zeros([360, 720])\n",
    "\n",
    "        # Initialize the combined arrays outside the taxa loop\n",
    "        diff_value_bin_combined = np.zeros([360, 720])\n",
    "        diff_sum_bin_combined = np.zeros([360, 720])\n",
    "        diff_combined = np.zeros([360, 720])\n",
    "\n",
    "        for row, taxa in enumerate(taxas):\n",
    "            # Reset the per model arrays for each taxa\n",
    "            diff_value_bin_models = []\n",
    "            diff_sum_bin_models = []\n",
    "            diff_models = []\n",
    "            percent_changes = []\n",
    "\n",
    "            for model in models:\n",
    "                for model_name in model_names:\n",
    "                    newvalue_path = f\"/storage/scratch/users/ch21o450/data/SR/{taxa}_{model}_{model_name}_{time}_{scenario}_summedprobs_newvalue.nc\"\n",
    "                    sumbin_path = f\"/storage/scratch/users/ch21o450/data/SR/{taxa}_{model}_{model_name}_{time}_{scenario}_summedprobs_sum.nc\"\n",
    "\n",
    "                    mean_value_bin = xr.open_dataset(newvalue_path, decode_times=False).to_array().isel(variable=0)\n",
    "                    mean_sum_bin = xr.open_dataset(sumbin_path, decode_times=False).to_array().isel(variable=0)\n",
    "\n",
    "                    # Calculate the differences\n",
    "                    diff_value_bin = mean_value_bin\n",
    "                    diff_sum_bin = mean_sum_bin\n",
    "                    diff = diff_sum_bin - diff_value_bin\n",
    "                    change_percent = ((diff_sum_bin - diff_value_bin) / (diff_value_bin)) * 100\n",
    "                    percent_changes.append(change_percent)\n",
    "\n",
    "\n",
    "                    # Append the ensemble mean to the overall results for this taxa\n",
    "                    diff_value_bin_combined_per_taxa[taxa] = diff_value_bin\n",
    "                    diff_sum_bin_combined_per_taxa[taxa] = diff_sum_bin\n",
    "                    diff_combined_per_taxa[taxa] = diff_ensemble\n",
    "\n",
    "                    # Calculate the overall species richness sum over all taxa\n",
    "                    diff_value_bin_combined = sum(diff_value_bin_combined_per_taxa.values())\n",
    "                    diff_sum_bin_combined = sum(diff_sum_bin_combined_per_taxa.values())\n",
    "                    diff_combined = sum(diff_combined_per_taxa.values())\n",
    "\n",
    "                    diff_newvalue = diff_value_bin_combined\n",
    "                    diff_sumbin = diff_sum_bin_combined\n",
    "                    diff_combined = diff_combined\n",
    "\n",
    "                    # Get rid of fine line at equator\n",
    "                    land_sea_mask = xr.open_dataset(\"/storage/workspaces/wa_climate/climate_trt/chari/LUH2/remapped_luh2_ssp126.nc\", decode_times=False).primf\n",
    "                    diff_newvalue_masked = diff_newvalue.where(land_sea_mask >= 0)\n",
    "                    diff_newvalue = diff_newvalue_masked.isel(time=0)\n",
    "\n",
    "                    output_path_diff_newvalue = f\"/storage/scratch/users/ch21o450/data/SRind/SR_CC_{time}_{scenario}_{model}_{model_name}.nc\"\n",
    "                    diff_newvalue.to_netcdf(output_path_diff_newvalue, format='NETCDF4')\n",
    "\n",
    "                    # Write out diff_sumbin as netCDF\n",
    "                    output_path_diff_sumbin = f\"/storage/scratch/users/ch21o450/data/SRind/SR_CCLUC_{time}_{scenario}_{model}_{model_name}.nc\"\n",
    "                    diff_sumbin.to_netcdf(output_path_diff_sumbin, format='NETCDF4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0415661d-a2ac-4194-8360-9a2a07062b08",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4af63f00-bc7d-4352-80b3-d835c0de72b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sensitivity Analysis SPECIES RICHNESS\n",
    "#newvalue_future and _historical and sumbin_future and _historical\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "models = [\"GAM\", \"GBM\"]\n",
    "taxas = [\"Bird\", \"Mammals\", \"Amphibians\"]\n",
    "scenarios = [\"rcp26\", \"rcp60\"]\n",
    "historical_time = 1146\n",
    "future_time = 65\n",
    "\n",
    "year_indices = {1146: '1995', 35: '2050', 65: '2080', 85: '2100'}\n",
    "\n",
    "for time in [historical_time, future_time]:\n",
    "    for scenario in scenarios:\n",
    "        # Create empty arrays for storing the results for each taxa separately\n",
    "        diff_value_bin_combined_per_taxa = {}\n",
    "        diff_sum_bin_combined_per_taxa = {}\n",
    "        diff_combined_per_taxa = {}\n",
    "\n",
    "        for taxa in taxas:\n",
    "            diff_value_bin_combined_per_taxa[taxa] = np.zeros([360, 720])\n",
    "            diff_sum_bin_combined_per_taxa[taxa] = np.zeros([360, 720])\n",
    "            diff_combined_per_taxa[taxa] = np.zeros([360, 720])\n",
    "\n",
    "        # Initialize the combined arrays outside the taxa loop\n",
    "        diff_value_bin_combined = np.zeros([360, 720])\n",
    "        diff_sum_bin_combined = np.zeros([360, 720])\n",
    "        diff_combined = np.zeros([360, 720])\n",
    "\n",
    "        for row, taxa in enumerate(taxas):\n",
    "            # Reset the per model arrays for each taxa\n",
    "            diff_value_bin_models = []\n",
    "            diff_sum_bin_models = []\n",
    "            diff_models = []\n",
    "            percent_changes = []\n",
    "\n",
    "            for model in models:\n",
    "                newvalue_path = f\"/storage/scratch/users/ch21o450/data/SR/SA_{taxa}_{model}_{time}_{scenario}_summedprobs_newvalue.nc\"\n",
    "                sumbin_path = f\"/storage/scratch/users/ch21o450/data/SR/SA_{taxa}_{model}_{time}_{scenario}_summedprobs_sum.nc\"\n",
    "\n",
    "                mean_value_bin = xr.open_dataset(newvalue_path, decode_times=False).to_array().isel(variable=0)\n",
    "                mean_sum_bin = xr.open_dataset(sumbin_path, decode_times=False).to_array().isel(variable=0)\n",
    "\n",
    "                # Calculate the differences\n",
    "                diff_value_bin = mean_value_bin\n",
    "                diff_sum_bin = mean_sum_bin\n",
    "                diff = diff_sum_bin - diff_value_bin\n",
    "                change_percent = ((diff_sum_bin - diff_value_bin) / (diff_value_bin)) * 100\n",
    "                percent_changes.append(change_percent)\n",
    "\n",
    "                # append the differences to the model-specific lists\n",
    "                diff_value_bin_models.append(diff_value_bin)\n",
    "                diff_sum_bin_models.append(diff_sum_bin)\n",
    "                diff_models.append(diff)\n",
    "\n",
    "            # Calculate the ensemble mean outside of the innermost loop\n",
    "            diff_value_bin_ensemble = xr.concat(diff_value_bin_models, dim=\"ensemble\").mean(dim=\"ensemble\")\n",
    "            diff_sum_bin_ensemble = xr.concat(diff_sum_bin_models, dim=\"ensemble\").mean(dim=\"ensemble\")\n",
    "\n",
    "            diff_value_bin_ensemble = diff_value_bin_ensemble\n",
    "            diff_sum_bin_ensemble = diff_sum_bin_ensemble\n",
    "            diff_ensemble = diff_sum_bin_ensemble - diff_value_bin_ensemble\n",
    "\n",
    "            # Append the ensemble mean to the overall results for this taxa\n",
    "            diff_value_bin_combined_per_taxa[taxa] = diff_value_bin_ensemble\n",
    "            diff_sum_bin_combined_per_taxa[taxa] = diff_sum_bin_ensemble\n",
    "            diff_combined_per_taxa[taxa] = diff_ensemble\n",
    "\n",
    "        # Calculate the overall species richness sum over all taxa\n",
    "        diff_value_bin_combined = sum(diff_value_bin_combined_per_taxa.values())\n",
    "        diff_sum_bin_combined = sum(diff_sum_bin_combined_per_taxa.values())\n",
    "        diff_combined = sum(diff_combined_per_taxa.values())\n",
    "\n",
    "        diff_newvalue = diff_value_bin_combined\n",
    "        diff_sumbin = diff_sum_bin_combined\n",
    "        diff_combined = diff_combined\n",
    "\n",
    "        # Get rid of fine line at equator\n",
    "        land_sea_mask = xr.open_dataset(\"/storage/workspaces/wa_climate/climate_trt/chari/LUH2/remapped_luh2_ssp126.nc\", decode_times=False).primf\n",
    "        diff_newvalue_masked = diff_newvalue.where(land_sea_mask >= 0)\n",
    "        diff_newvalue = diff_newvalue_masked.isel(time=0)\n",
    "\n",
    "        output_path_diff_newvalue = f\"/storage/scratch/users/ch21o450/data/SR/SR_CC_{time}_{scenario}_SA.nc\"\n",
    "        diff_newvalue.to_netcdf(output_path_diff_newvalue, format='NETCDF4')\n",
    "\n",
    "        # Write out diff_sumbin as netCDF\n",
    "        output_path_diff_sumbin = f\"/storage/scratch/users/ch21o450/data/SR/SR_CCLUC_{time}_{scenario}_SA.nc\"\n",
    "        diff_sumbin.to_netcdf(output_path_diff_sumbin, format='NETCDF4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167663d0-7532-41fa-ad81-cd4f392251e2",
   "metadata": {},
   "source": [
    "# Dispersal sceenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "489814d7-ae9c-4d86-af30-968e1c0cc566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dispersal scenario\n",
    "#newvalue_future and _historical and sumbin_future and _historical\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "models = [\"GAM\", \"GBM\"]\n",
    "taxas = [\"Bird\", \"Mammals\", \"Amphibians\"]\n",
    "scenarios = [\"rcp26\", \"rcp60\"]\n",
    "#historical_time = 1146\n",
    "future_time = 1146\n",
    "\n",
    "year_indices = {1146: '1995', 35: '2050', 65: '2080', 85: '2100'}\n",
    "\n",
    "for time in [future_time]:\n",
    "    for scenario in scenarios:\n",
    "        # Create empty arrays for storing the results for each taxa separately\n",
    "        diff_value_bin_combined_per_taxa = {}\n",
    "        diff_sum_bin_combined_per_taxa = {}\n",
    "        diff_combined_per_taxa = {}\n",
    "\n",
    "        for taxa in taxas:\n",
    "            diff_value_bin_combined_per_taxa[taxa] = np.zeros([360, 720])\n",
    "            diff_sum_bin_combined_per_taxa[taxa] = np.zeros([360, 720])\n",
    "            diff_combined_per_taxa[taxa] = np.zeros([360, 720])\n",
    "\n",
    "        # Initialize the combined arrays outside the taxa loop\n",
    "        diff_value_bin_combined = np.zeros([360, 720])\n",
    "        diff_sum_bin_combined = np.zeros([360, 720])\n",
    "        diff_combined = np.zeros([360, 720])\n",
    "\n",
    "        for row, taxa in enumerate(taxas):\n",
    "            # Reset the per model arrays for each taxa\n",
    "            diff_value_bin_models = []\n",
    "            diff_sum_bin_models = []\n",
    "            diff_models = []\n",
    "            percent_changes = []\n",
    "\n",
    "            for model in models:\n",
    "                newvalue_path = f\"/storage/scratch/users/ch21o450/data/SR/Dispersal2_{taxa}_{model}_{time}_{scenario}_summedprobs_newvalue.nc\"\n",
    "                sumbin_path = f\"/storage/scratch/users/ch21o450/data/SR/Dispersal2_{taxa}_{model}_{time}_{scenario}_summedprobs_sum.nc\"\n",
    "\n",
    "                mean_value_bin = xr.open_dataset(newvalue_path, decode_times=False).to_array().isel(variable=0)\n",
    "                mean_sum_bin = xr.open_dataset(sumbin_path, decode_times=False).to_array().isel(variable=0)\n",
    "\n",
    "                # Calculate the differences\n",
    "                diff_value_bin = mean_value_bin\n",
    "                diff_sum_bin = mean_sum_bin\n",
    "                diff = diff_sum_bin - diff_value_bin\n",
    "                change_percent = ((diff_sum_bin - diff_value_bin) / (diff_value_bin)) * 100\n",
    "                percent_changes.append(change_percent)\n",
    "\n",
    "                # append the differences to the model-specific lists\n",
    "                diff_value_bin_models.append(diff_value_bin)\n",
    "                diff_sum_bin_models.append(diff_sum_bin)\n",
    "                diff_models.append(diff)\n",
    "\n",
    "            # Calculate the ensemble mean outside of the innermost loop\n",
    "            diff_value_bin_ensemble = xr.concat(diff_value_bin_models, dim=\"ensemble\").mean(dim=\"ensemble\")\n",
    "            diff_sum_bin_ensemble = xr.concat(diff_sum_bin_models, dim=\"ensemble\").mean(dim=\"ensemble\")\n",
    "\n",
    "            diff_value_bin_ensemble = diff_value_bin_ensemble\n",
    "            diff_sum_bin_ensemble = diff_sum_bin_ensemble\n",
    "            diff_ensemble = diff_sum_bin_ensemble - diff_value_bin_ensemble\n",
    "\n",
    "            # Append the ensemble mean to the overall results for this taxa\n",
    "            diff_value_bin_combined_per_taxa[taxa] = diff_value_bin_ensemble\n",
    "            diff_sum_bin_combined_per_taxa[taxa] = diff_sum_bin_ensemble\n",
    "            diff_combined_per_taxa[taxa] = diff_ensemble\n",
    "\n",
    "        # Calculate the overall species richness sum over all taxa\n",
    "        diff_value_bin_combined = sum(diff_value_bin_combined_per_taxa.values())\n",
    "        diff_sum_bin_combined = sum(diff_sum_bin_combined_per_taxa.values())\n",
    "        diff_combined = sum(diff_combined_per_taxa.values())\n",
    "\n",
    "        diff_newvalue = diff_value_bin_combined\n",
    "        diff_sumbin = diff_sum_bin_combined\n",
    "        diff_combined = diff_combined\n",
    "\n",
    "        # Get rid of fine line at equator\n",
    "        land_sea_mask = xr.open_dataset(\"/storage/workspaces/wa_climate/climate_trt/chari/LUH2/remapped_luh2_ssp126.nc\", decode_times=False).primf\n",
    "        diff_newvalue_masked = diff_newvalue.where(land_sea_mask >= 0)\n",
    "        diff_newvalue = diff_newvalue_masked.isel(time=0)\n",
    "\n",
    "        output_path_diff_newvalue = f\"/storage/scratch/users/ch21o450/data/SR/SR_CC_{time}_{scenario}_dispersal2.nc\"\n",
    "        diff_newvalue.to_netcdf(output_path_diff_newvalue, format='NETCDF4')\n",
    "\n",
    "        # Write out diff_sumbin as netCDF\n",
    "        output_path_diff_sumbin = f\"/storage/scratch/users/ch21o450/data/SR/SR_CCLUC_{time}_{scenario}_dispersal2.nc\"\n",
    "        diff_sumbin.to_netcdf(output_path_diff_sumbin, format='NETCDF4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41302206-b72e-45b3-897b-659004d0ca55",
   "metadata": {},
   "source": [
    "# Future only SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db9cb4d6-8312-4289-9c40-b8600fb7b9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### write out cc anc luc (future only) per scenario\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "models =  [\"GAM\",\"GBM\"]\n",
    "taxas = [\"Bird\",\"Mammals\",\"Amphibians\"]\n",
    "scenarios = [\"rcp26\"]\n",
    "historical_time= 1146\n",
    "future_time=85\n",
    "\n",
    "model_names = ['GFDL-ESM2M', 'IPSL-CM5A-LR', 'HadGEM2-ES', 'MIROC5']\n",
    "years = ['1845', '1990', '1995', '2009', '2010', '2020', '2026', '2032', '2048', '2050','2052', '2056', '2080', '2100', '2150', '2200', '2250']\n",
    "\n",
    "year_indices = {1146: '1995', 35: '2050', 65: '2080', 85: '2100'}\n",
    "# Create empty arrays for storing the results for each taxa separately\n",
    "diff_value_bin_combined_per_taxa = {}\n",
    "diff_sum_bin_combined_per_taxa = {}\n",
    "diff_combined_per_taxa = {}\n",
    "\n",
    "for taxa in taxas:\n",
    "\n",
    "    diff_value_bin_combined_per_taxa[taxa] = np.zeros([360, 720])\n",
    "    diff_sum_bin_combined_per_taxa[taxa] = np.zeros([360, 720])\n",
    "    diff_combined_per_taxa[taxa] = np.zeros([360, 720])\n",
    "\n",
    "for row, scenario in enumerate(scenarios):\n",
    "\n",
    "    # Initialize the combined arrays outside the taxa loop\n",
    "    diff_value_bin_combined = np.zeros([360, 720])\n",
    "    diff_sum_bin_combined = np.zeros([360, 720])\n",
    "    diff_combined = np.zeros([360, 720])\n",
    "\n",
    "    for taxa in taxas:\n",
    "        # Reset the per model arrays for each taxa\n",
    "        diff_value_bin_models = []\n",
    "        diff_sum_bin_models = []\n",
    "        diff_models = []\n",
    "        percent_changes = []\n",
    "\n",
    "\n",
    "        for model in models:\n",
    "            newvalue_hist = f\"/storage/scratch/users/ch21o450/data/SR/{taxa}_{model}_{historical_time}_{scenario}_summedprobs_newvalue.nc\"\n",
    "            sumbin_hist = f\"/storage/scratch/users/ch21o450/data/SR/{taxa}_{model}_{historical_time}_{scenario}_summedprobs_sum.nc\"\n",
    "\n",
    "\n",
    "            mean_value_bin_hist = xr.open_dataset(newvalue_hist, decode_times=False).to_array().isel(variable=0)\n",
    "            mean_sum_bin_hist = xr.open_dataset(sumbin_hist, decode_times=False).to_array().isel(variable=0)\n",
    "\n",
    "            newvalue_fut = f\"/storage/scratch/users/ch21o450/data/SR/{taxa}_{model}_{future_time}_{scenario}_summedprobs_newvalue.nc\"\n",
    "            sumbin_fut = f\"/storage/scratch/users/ch21o450/data/SR/{taxa}_{model}_{future_time}_{scenario}_summedprobs_sum.nc\"\n",
    "\n",
    "\n",
    "            mean_value_bin_future = xr.open_dataset(newvalue_fut, decode_times=False).to_array()\n",
    "            mean_sum_bin_future = xr.open_dataset(sumbin_fut, decode_times=False).to_array()\n",
    "            mean_sum_bin_future = mean_sum_bin_future.isel(variable=0)\n",
    "\n",
    "            # Calculate the differences\n",
    "            diff_value_bin = mean_value_bin_future\n",
    "            diff_sum_bin = mean_sum_bin_future\n",
    "            diff = diff_sum_bin - diff_value_bin\n",
    "            change_percent = ((diff_sum_bin - diff_value_bin) / (diff_value_bin)) * 100  # added small value to avoid division by zero\n",
    "            percent_changes.append(change_percent)\n",
    "\n",
    "            # append the differences to the model-specific lists\n",
    "            diff_value_bin_models.append(diff_value_bin)\n",
    "            diff_sum_bin_models.append(diff_sum_bin)\n",
    "            diff_models.append(diff)\n",
    "\n",
    "# Calculate the ensemble mean outside of the innermost loop\n",
    "        diff_value_bin_ensemble = xr.concat(diff_value_bin_models, dim=\"ensemble\").mean(dim=\"ensemble\")\n",
    "        diff_sum_bin_ensemble = xr.concat(diff_sum_bin_models, dim=\"ensemble\").mean(dim=\"ensemble\")\n",
    "\n",
    "        diff_value_bin_ensemble = diff_value_bin_ensemble.isel(variable=0)\n",
    "        diff_sum_bin_ensemble = diff_sum_bin_ensemble\n",
    "        diff_ensemble = diff_sum_bin_ensemble - diff_value_bin_ensemble\n",
    "\n",
    "        # Append the ensemble mean to the overall results for this taxa\n",
    "        diff_value_bin_combined_per_taxa[taxa] = diff_value_bin_ensemble\n",
    "        diff_sum_bin_combined_per_taxa[taxa] = diff_sum_bin_ensemble\n",
    "        diff_combined_per_taxa[taxa] = diff_ensemble\n",
    "\n",
    "    # Calculate the overall species richness sum over all taxa\n",
    "    diff_value_bin_combined = sum(diff_value_bin_combined_per_taxa.values())\n",
    "    diff_sum_bin_combined = sum(diff_sum_bin_combined_per_taxa.values())\n",
    "    diff_combined = sum(diff_combined_per_taxa.values())\n",
    "\n",
    "\n",
    "\n",
    "    diff_newvalue= diff_value_bin_combined\n",
    "    diff_sumbin = diff_sum_bin_combined\n",
    "    diff = diff_combined\n",
    "\n",
    "    #Get rid off fine line at equator\n",
    "    land_sea_mask = xr.open_dataset(\"/storage/workspaces/wa_climate/climate_trt/chari/LUH2/remapped_luh2_ssp126.nc\", decode_times=False).primf\n",
    "    diff_newvalue_masked = diff_newvalue.where(land_sea_mask >= 0)\n",
    "    diff_newvalue = diff_newvalue_masked.isel(time=0)\n",
    "\n",
    "\n",
    "    output_path_diff_newvalue = f\"/storage/scratch/users/ch21o450/data/SR/cc_{future_time}_{scenario}.nc\"\n",
    "    diff_newvalue.to_netcdf(output_path_diff_newvalue, format='NETCDF4')\n",
    "\n",
    "    # Write out diff_sumbin as netCDF\n",
    "    output_path_diff_sumbin = f\"/storage/scratch/users/ch21o450/data/SR/ccluc_{future_time}_{scenario}.nc\"\n",
    "    diff_sumbin.to_netcdf(output_path_diff_sumbin, format='NETCDF4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fded69-621d-44c4-8b01-b262e67acaa4",
   "metadata": {},
   "source": [
    "# Protected Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a5d1078-d536-4265-95d3-5c20348e8d93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: b'/storage/scratch/users/ch21o450/data/intermediate_results/PA_Amphibians_GAM_65_rcp26_summedprobs_newvalue.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36m_acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                 \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/lru_cache.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('/storage/scratch/users/ch21o450/data/intermediate_results/PA_Amphibians_GAM_65_rcp26_summedprobs_newvalue.nc',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), '5846c2b5-f512-46e1-8207-360332e7fc36']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/1657487/ipykernel_99755/2550990618.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0msumbin_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"/storage/scratch/users/ch21o450/data/intermediate_results/PA_{taxa}_{model}_{time}_{scenario}_summedprobs_sum.nc\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0mmean_value_bin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewvalue_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0mmean_sum_bin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msumbin_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0moverwrite_encoded_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"overwrite_encoded_chunks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m     backend_ds = backend.open_dataset(\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0mdrop_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_variables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, lock, autoclose)\u001b[0m\n\u001b[1;32m    575\u001b[0m     ):\n\u001b[1;32m    576\u001b[0m         \u001b[0mfilename_or_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_normalize_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         store = NetCDF4DataStore.open(\n\u001b[0m\u001b[1;32m    578\u001b[0m             \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mnetCDF4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         )\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautoclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_remote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_remote_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen_store_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m_acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneeds_lock\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m             \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nc4_require_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software.el7/software/Anaconda3/2021.11-foss-2021a/lib/python3.9/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36macquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0macquire_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;34m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_acquire_with_cache_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneeds_lock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36m_acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                 \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                     \u001b[0;31m# ensure file doesn't get overridden when opened again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'/storage/scratch/users/ch21o450/data/intermediate_results/PA_Amphibians_GAM_65_rcp26_summedprobs_newvalue.nc'"
     ]
    }
   ],
   "source": [
    "#PA\n",
    "#newvalue_future and _historical and sumbin_future and _historical\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "models = [\"GAM\", \"GBM\"]\n",
    "taxas = [\"Bird\", \"Mammals\", \"Amphibians\"]\n",
    "scenarios = [\"rcp26\", \"rcp60\"]\n",
    "historical_time = 1146\n",
    "future_time = 65\n",
    "\n",
    "year_indices = {1146: '1995', 35: '2050', 65: '2080', 85: '2100'}\n",
    "\n",
    "for time in [ future_time]:\n",
    "    for scenario in scenarios:\n",
    "        # Create empty arrays for storing the results for each taxa separately\n",
    "        diff_value_bin_combined_per_taxa = {}\n",
    "        diff_sum_bin_combined_per_taxa = {}\n",
    "        diff_combined_per_taxa = {}\n",
    "\n",
    "        for taxa in taxas:\n",
    "            diff_value_bin_combined_per_taxa[taxa] = np.zeros([360, 720])\n",
    "            diff_sum_bin_combined_per_taxa[taxa] = np.zeros([360, 720])\n",
    "            diff_combined_per_taxa[taxa] = np.zeros([360, 720])\n",
    "\n",
    "        # Initialize the combined arrays outside the taxa loop\n",
    "        diff_value_bin_combined = np.zeros([360, 720])\n",
    "        diff_sum_bin_combined = np.zeros([360, 720])\n",
    "        diff_combined = np.zeros([360, 720])\n",
    "\n",
    "        for row, taxa in enumerate(taxas):\n",
    "            # Reset the per model arrays for each taxa\n",
    "            diff_value_bin_models = []\n",
    "            diff_sum_bin_models = []\n",
    "            diff_models = []\n",
    "            percent_changes = []\n",
    "\n",
    "            for model in models:\n",
    "                newvalue_path = f\"/storage/scratch/users/ch21o450/data/intermediate_results/PA_{taxa}_{model}_{time}_{scenario}_summedprobs_newvalue.nc\"\n",
    "                sumbin_path = f\"/storage/scratch/users/ch21o450/data/intermediate_results/PA_{taxa}_{model}_{time}_{scenario}_summedprobs_sum.nc\"\n",
    "\n",
    "                mean_value_bin = xr.open_dataset(newvalue_path, decode_times=False).to_array().isel(variable=0)\n",
    "                mean_sum_bin = xr.open_dataset(sumbin_path, decode_times=False).to_array().isel(variable=0)\n",
    "\n",
    "                # Calculate the differences\n",
    "                diff_value_bin = mean_value_bin\n",
    "                diff_sum_bin = mean_sum_bin\n",
    "                diff = diff_sum_bin - diff_value_bin\n",
    "                change_percent = ((diff_sum_bin - diff_value_bin) / (diff_value_bin)) * 100\n",
    "                percent_changes.append(change_percent)\n",
    "\n",
    "                # append the differences to the model-specific lists\n",
    "                diff_value_bin_models.append(diff_value_bin)\n",
    "                diff_sum_bin_models.append(diff_sum_bin)\n",
    "                diff_models.append(diff)\n",
    "\n",
    "            # Calculate the ensemble mean outside of the innermost loop\n",
    "            diff_value_bin_ensemble = xr.concat(diff_value_bin_models, dim=\"ensemble\").mean(dim=\"ensemble\")\n",
    "            diff_sum_bin_ensemble = xr.concat(diff_sum_bin_models, dim=\"ensemble\").mean(dim=\"ensemble\")\n",
    "\n",
    "            diff_value_bin_ensemble = diff_value_bin_ensemble\n",
    "            diff_sum_bin_ensemble = diff_sum_bin_ensemble\n",
    "            diff_ensemble = diff_sum_bin_ensemble - diff_value_bin_ensemble\n",
    "\n",
    "            # Append the ensemble mean to the overall results for this taxa\n",
    "            diff_value_bin_combined_per_taxa[taxa] = diff_value_bin_ensemble\n",
    "            diff_sum_bin_combined_per_taxa[taxa] = diff_sum_bin_ensemble\n",
    "            diff_combined_per_taxa[taxa] = diff_ensemble\n",
    "\n",
    "        # Calculate the overall species richness sum over all taxa\n",
    "        diff_value_bin_combined = sum(diff_value_bin_combined_per_taxa.values())\n",
    "        diff_sum_bin_combined = sum(diff_sum_bin_combined_per_taxa.values())\n",
    "        diff_combined = sum(diff_combined_per_taxa.values())\n",
    "\n",
    "        diff_newvalue = diff_value_bin_combined\n",
    "        diff_sumbin = diff_sum_bin_combined\n",
    "        diff_combined = diff_combined\n",
    "\n",
    "        # Get rid of fine line at equator\n",
    "        land_sea_mask = xr.open_dataset(\"/storage/workspaces/wa_climate/climate_trt/chari/LUH2/remapped_luh2_ssp126.nc\", decode_times=False).primf\n",
    "        diff_newvalue_masked = diff_newvalue.where(land_sea_mask >= 0)\n",
    "        diff_newvalue = diff_newvalue_masked.isel(time=0)\n",
    "\n",
    "        output_path_diff_newvalue = f\"/storage/scratch/users/ch21o450/data/SRnew/SR_CC_{time}_{scenario}_PA.nc\"\n",
    "        diff_newvalue.to_netcdf(output_path_diff_newvalue, format='NETCDF4')\n",
    "\n",
    "        # Write out diff_sumbin as netCDF\n",
    "        output_path_diff_sumbin = f\"/storage/scratch/users/ch21o450/data/SRnew/SR_CCLUC_{time}_{scenario}_PA.nc\"\n",
    "        diff_sumbin.to_netcdf(output_path_diff_sumbin, format='NETCDF4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9de12c4-2d71-48dd-85df-e0f138c3e3b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sanity Check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beec1c5f-8c33-43bd-8592-2894a2cb2586",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: b'/storage/scratch/users/ch21o450/data/LandClim_Output_sanity/Bird_GAM_1146_rcp60_summedprobs_newvalue.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36m_acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                 \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/lru_cache.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('/storage/scratch/users/ch21o450/data/LandClim_Output_sanity/Bird_GAM_1146_rcp60_summedprobs_newvalue.nc',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), '99605c2b-5c4d-46c0-b3bf-b29a78782f63']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/1657487/ipykernel_99755/1683894773.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0msumbin_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"/storage/scratch/users/ch21o450/data/LandClim_Output_sanity/{taxa}_{model}_{time}_{scenario}_summedprobs_sum.nc\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mmean_value_bin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewvalue_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                 \u001b[0mmean_sum_bin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msumbin_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0moverwrite_encoded_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"overwrite_encoded_chunks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m     backend_ds = backend.open_dataset(\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0mdrop_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_variables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, lock, autoclose)\u001b[0m\n\u001b[1;32m    575\u001b[0m     ):\n\u001b[1;32m    576\u001b[0m         \u001b[0mfilename_or_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_normalize_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         store = NetCDF4DataStore.open(\n\u001b[0m\u001b[1;32m    578\u001b[0m             \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mnetCDF4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         )\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautoclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_remote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_remote_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen_store_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m_acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneeds_lock\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m             \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nc4_require_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software.el7/software/Anaconda3/2021.11-foss-2021a/lib/python3.9/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36macquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0macquire_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;34m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_acquire_with_cache_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneeds_lock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36m_acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                 \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                     \u001b[0;31m# ensure file doesn't get overridden when opened again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'/storage/scratch/users/ch21o450/data/LandClim_Output_sanity/Bird_GAM_1146_rcp60_summedprobs_newvalue.nc'"
     ]
    }
   ],
   "source": [
    "#Dispersal scenario\n",
    "#newvalue_future and _historical and sumbin_future and _historical\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "models = [\"GAM\", \"GBM\"]\n",
    "taxas = [\"Bird\", \"Mammals\", \"Amphibians\"]\n",
    "scenarios = [ \"rcp60\"]\n",
    "#historical_time = 1146\n",
    "future_time = 1146\n",
    "\n",
    "year_indices = {1146: '1995', 35: '2050', 65: '2080', 85: '2100'}\n",
    "\n",
    "for time in [future_time]:\n",
    "    for scenario in scenarios:\n",
    "        # Create empty arrays for storing the results for each taxa separately\n",
    "        diff_value_bin_combined_per_taxa = {}\n",
    "        diff_sum_bin_combined_per_taxa = {}\n",
    "        diff_combined_per_taxa = {}\n",
    "\n",
    "        for taxa in taxas:\n",
    "            diff_value_bin_combined_per_taxa[taxa] = np.zeros([360, 720])\n",
    "            diff_sum_bin_combined_per_taxa[taxa] = np.zeros([360, 720])\n",
    "            diff_combined_per_taxa[taxa] = np.zeros([360, 720])\n",
    "\n",
    "        # Initialize the combined arrays outside the taxa loop\n",
    "        diff_value_bin_combined = np.zeros([360, 720])\n",
    "        diff_sum_bin_combined = np.zeros([360, 720])\n",
    "        diff_combined = np.zeros([360, 720])\n",
    "\n",
    "        for row, taxa in enumerate(taxas):\n",
    "            # Reset the per model arrays for each taxa\n",
    "            diff_value_bin_models = []\n",
    "            diff_sum_bin_models = []\n",
    "            diff_models = []\n",
    "            percent_changes = []\n",
    "\n",
    "            for model in models:\n",
    "                newvalue_path = f\"/storage/scratch/users/ch21o450/data/LandClim_Output_sanity/{taxa}_{model}_{time}_{scenario}_summedprobs_newvalue.nc\"\n",
    "                sumbin_path = f\"/storage/scratch/users/ch21o450/data/LandClim_Output_sanity/{taxa}_{model}_{time}_{scenario}_summedprobs_sum.nc\"\n",
    "\n",
    "                mean_value_bin = xr.open_dataset(newvalue_path, decode_times=False).to_array().isel(variable=0)\n",
    "                mean_sum_bin = xr.open_dataset(sumbin_path, decode_times=False).to_array().isel(variable=0)\n",
    "\n",
    "                # Calculate the differences\n",
    "                diff_value_bin = mean_value_bin\n",
    "                diff_sum_bin = mean_sum_bin\n",
    "                diff = diff_sum_bin - diff_value_bin\n",
    "                change_percent = ((diff_sum_bin - diff_value_bin) / (diff_value_bin)) * 100\n",
    "                percent_changes.append(change_percent)\n",
    "\n",
    "                # append the differences to the model-specific lists\n",
    "                diff_value_bin_models.append(diff_value_bin)\n",
    "                diff_sum_bin_models.append(diff_sum_bin)\n",
    "                diff_models.append(diff)\n",
    "\n",
    "            # Calculate the ensemble mean outside of the innermost loop\n",
    "            diff_value_bin_ensemble = xr.concat(diff_value_bin_models, dim=\"ensemble\").mean(dim=\"ensemble\")\n",
    "            diff_sum_bin_ensemble = xr.concat(diff_sum_bin_models, dim=\"ensemble\").mean(dim=\"ensemble\")\n",
    "\n",
    "            diff_value_bin_ensemble = diff_value_bin_ensemble\n",
    "            diff_sum_bin_ensemble = diff_sum_bin_ensemble\n",
    "            diff_ensemble = diff_sum_bin_ensemble - diff_value_bin_ensemble\n",
    "\n",
    "            # Append the ensemble mean to the overall results for this taxa\n",
    "            diff_value_bin_combined_per_taxa[taxa] = diff_value_bin_ensemble\n",
    "            diff_sum_bin_combined_per_taxa[taxa] = diff_sum_bin_ensemble\n",
    "            diff_combined_per_taxa[taxa] = diff_ensemble\n",
    "\n",
    "        # Calculate the overall species richness sum over all taxa\n",
    "        diff_value_bin_combined = sum(diff_value_bin_combined_per_taxa.values())\n",
    "        diff_sum_bin_combined = sum(diff_sum_bin_combined_per_taxa.values())\n",
    "        diff_combined = sum(diff_combined_per_taxa.values())\n",
    "\n",
    "        diff_newvalue = diff_value_bin_combined\n",
    "        diff_sumbin = diff_sum_bin_combined\n",
    "        diff_combined = diff_combined\n",
    "\n",
    "        # Get rid of fine line at equator\n",
    "        land_sea_mask = xr.open_dataset(\"/storage/workspaces/wa_climate/climate_trt/chari/LUH2/remapped_luh2_ssp126.nc\", decode_times=False).primf\n",
    "        diff_newvalue_masked = diff_newvalue.where(land_sea_mask >= 0)\n",
    "        diff_newvalue = diff_newvalue_masked.isel(time=0)\n",
    "\n",
    "        output_path_diff_newvalue = f\"/storage/scratch/users/ch21o450/data/SR/SR_CC_{time}_{scenario}_sanity.nc\"\n",
    "        diff_newvalue.to_netcdf(output_path_diff_newvalue, format='NETCDF4')\n",
    "\n",
    "        # Write out diff_sumbin as netCDF\n",
    "        output_path_diff_sumbin = f\"/storage/scratch/users/ch21o450/data/SR/SR_CCLUC_{time}_{scenario}_sanity.nc\"\n",
    "        diff_sumbin.to_netcdf(output_path_diff_sumbin, format='NETCDF4')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
