{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a2ad856-f03e-4636-9df6-2416e62edd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "#pip install  rioxarray==0.3.1\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import cartopy.crs as ccrs\n",
    "import rasterio\n",
    "import os\n",
    "import matplotlib.colors\n",
    "scriptsdir = os.getcwd()\n",
    "from scipy.interpolate import griddata\n",
    "from functools import reduce\n",
    "import xarray\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f73069ce-17a9-44de-8edd-2d53e2e1daac",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxas = [\"Mammals\",\"Reptile\",\"Amphibians\"]\n",
    "models =[\"GAM\",\"GBM\"] \n",
    "time=[35]\n",
    "years= ['1845', '1990', '1995', '2009', '2010', '2020', '2026', '2032', '2048', '2050','2052', '2056', '2080', '2100', '2150', '2200', '2250']\n",
    "year_indices = {35: 9, 65: 12, 85: 13}\n",
    "selected_year = years[year_indices[time[0]]]\n",
    "if time[0] == 35 or time[0] == 65:\n",
    "    model_names = ['GFDL-ESM2M', 'IPSL-CM5A-LR', 'HadGEM2-ES', 'MIROC5']\n",
    "    bioscen_model_names = ['GFDL.ESM2M', 'IPSL.CM5A-LR', 'HadGEM2.ES', 'MIROC5']\n",
    "elif time[0] == 85:\n",
    "    model_names = ['IPSL-CM5A-LR', 'HadGEM2-ES', 'MIROC5']\n",
    "    bioscen_model_names = ['IPSL.CM5A-LR', 'HadGEM2.ES', 'MIROC5']\n",
    "    \n",
    "scenarios = [\"rcp26\",\"rcp60\"]\n",
    "ssprcps_shorts = [\"ssp126\",\"ssp460\"]\n",
    "ssprcps_longs = [\"ssp1_rcp2.6\",\"ssp4_rcp6.0\"]\n",
    "combinations = list(itertools.product(models, model_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d13dab7-46c5-4fda-87c2-884724154cd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "coords is not dict-like, but it has 2 items, which does not match the 3 dimensions of the data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/49693169/ipykernel_40749/3439216466.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcalculate_landclim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaxas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbioscen_model_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscenarios\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssprcps_longs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssprcps_shorts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/local/49693169/ipykernel_40749/3631578435.py\u001b[0m in \u001b[0;36mcalculate_landclim\u001b[0;34m(taxas, models, model_names, bioscen_model_names, scenarios, ssprcps_longs, ssprcps_shorts, time)\u001b[0m\n\u001b[1;32m     88\u001b[0m                                     \u001b[0misimip_lons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misimip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                                     \u001b[0mda_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_empty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misimip_lats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misimip_lons\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lats'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lons'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                                     \u001b[0mda_landclim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mda_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mda_landuse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, coords, dims, name, attrs, indexes, fastpath)\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_data_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_compatible_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_infer_coords_and_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m             \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             indexes = dict(\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36m_infer_coords_and_dims\u001b[0;34m(shape, coords, dims)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[0;32m--> 102\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0;34mf\"coords is not dict-like, but it has {len(coords)} items, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;34mf\"which does not match the {len(shape)} dimensions of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: coords is not dict-like, but it has 2 items, which does not match the 3 dimensions of the data"
     ]
    }
   ],
   "source": [
    "calculate_landclim(taxas, models, model_names, bioscen_model_names, scenarios, ssprcps_longs, ssprcps_shorts, time=time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b301d1-06e8-46c5-a713-0e99758e75e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e5227bd-e530-471f-9008-e9c499275217",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "isimip = xr.open_dataarray(\"/storage/workspaces/wa_climate/climate_trt/data/ISIMIP/ISIMIP3b/InputData/GCM/global/miroc6_r1i1p1f1_w5e5_ssp585_tasmin_global_daily_2071_2080.nc\")\n",
    "\n",
    "\n",
    "ncfname = LandUseList\n",
    "da_landuse =  xarray.open_dataset(ncfname, decode_times=False)\n",
    "da_landuse = da_landuse.isel(time=time)\n",
    "\n",
    "#prifdf_bin = xr.where(prifdf > 0, 1, 0)\n",
    "df_sdm =df\n",
    "da_landuse = da_landuse.coarsen(lon=2).mean().coarsen(lat=2).mean()\n",
    "\n",
    "#build an empty np.array \n",
    "np_empty = np.zeros_like(da_landuse['primf'].values, dtype=float)\n",
    "\n",
    "isimip_lats = isimip['lat'].values\n",
    "isimip_lons = isimip['lon'].values\n",
    "\n",
    "da_empty = xr.DataArray(np_empty, coords=[time, isimip_lats, isimip_lons], dims=['time','lats','lons'])\n",
    "da_landclim = da_empty.assign_attrs(da_landuse)\n",
    "\n",
    "keys = [\"primn\" if row[f\"LUH{i}\"] == \"primn\" else row[f\"LUH{i}\"] for _, row in Habitats_suitable.iterrows() for i in range(1, 5) if pd.notna(row[f\"LUH{i}\"])]\n",
    "keys = list(set(keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f258c7ea-a607-4efe-84ae-b20e0968e98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray (time: 1, lats: 360, lons: 720)&gt;\n",
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])\n",
       "Coordinates:\n",
       "  * time     (time) int64 35\n",
       "  * lats     (lats) float64 89.75 89.25 88.75 88.25 ... -88.75 -89.25 -89.75\n",
       "  * lons     (lons) float64 -179.8 -179.2 -178.8 -178.2 ... 178.8 179.2 179.8</pre><div class='xr-wrap' hidden><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'></div><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 1</li><li><span class='xr-has-index'>lats</span>: 360</li><li><span class='xr-has-index'>lons</span>: 720</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-a418f050-7cf4-4bda-af9c-37bd841fc9d7' class='xr-array-in' type='checkbox' checked><label for='section-a418f050-7cf4-4bda-af9c-37bd841fc9d7' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0</span></div><div class='xr-array-data'><pre>array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])</pre></div></div></li><li class='xr-section-item'><input id='section-0765a92d-2e8d-4693-9378-b00713b158f7' class='xr-section-summary-in' type='checkbox'  checked><label for='section-0765a92d-2e8d-4693-9378-b00713b158f7' class='xr-section-summary' >Coordinates: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>35</div><input id='attrs-d1166606-5eed-4e1a-8536-11fdafcda26a' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-d1166606-5eed-4e1a-8536-11fdafcda26a' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-9a580898-31ea-4dc7-bb5b-5251c9064666' class='xr-var-data-in' type='checkbox'><label for='data-9a580898-31ea-4dc7-bb5b-5251c9064666' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([35])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lats</span></div><div class='xr-var-dims'>(lats)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>89.75 89.25 88.75 ... -89.25 -89.75</div><input id='attrs-5363221c-e760-4cb8-b43b-cc4301469e2b' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-5363221c-e760-4cb8-b43b-cc4301469e2b' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-f0659932-e288-426e-8012-0dbd4e9d00ef' class='xr-var-data-in' type='checkbox'><label for='data-f0659932-e288-426e-8012-0dbd4e9d00ef' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([ 89.75,  89.25,  88.75, ..., -88.75, -89.25, -89.75])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lons</span></div><div class='xr-var-dims'>(lons)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-179.8 -179.2 ... 179.2 179.8</div><input id='attrs-12fe063c-64a0-4034-bb08-d85decc1e85d' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-12fe063c-64a0-4034-bb08-d85decc1e85d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-635b00a6-7ec5-4ee7-b8aa-060f505aaab2' class='xr-var-data-in' type='checkbox'><label for='data-635b00a6-7ec5-4ee7-b8aa-060f505aaab2' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([-179.75, -179.25, -178.75, ...,  178.75,  179.25,  179.75])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-eebd6f69-57e0-477f-82e1-497615aa8b78' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-eebd6f69-57e0-477f-82e1-497615aa8b78' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray (time: 1, lats: 360, lons: 720)>\n",
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])\n",
       "Coordinates:\n",
       "  * time     (time) int64 35\n",
       "  * lats     (lats) float64 89.75 89.25 88.75 88.25 ... -88.75 -89.25 -89.75\n",
       "  * lons     (lons) float64 -179.8 -179.2 -178.8 -178.2 ... 178.8 179.2 179.8"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7fa8cd88-323c-4e15-a377-12730af914fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3653, 360, 720)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_empty.shape\n",
    "isimip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "102ad452-cc27-477e-8b6b-f9d97cf0b6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_empty = np.zeros_like(da_landuse['primf'].values, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c35e447-2fee-4da0-97b7-d6efa41114ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "coords is not dict-like, but it has 2 items, which does not match the 3 dimensions of the data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/49693169/ipykernel_40749/2286984554.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mda_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_empty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misimip_lats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misimip_lons\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lats'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lons'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, coords, dims, name, attrs, indexes, fastpath)\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_data_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_compatible_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_infer_coords_and_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m             \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             indexes = dict(\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36m_infer_coords_and_dims\u001b[0;34m(shape, coords, dims)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[0;32m--> 102\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0;34mf\"coords is not dict-like, but it has {len(coords)} items, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;34mf\"which does not match the {len(shape)} dimensions of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: coords is not dict-like, but it has 2 items, which does not match the 3 dimensions of the data"
     ]
    }
   ],
   "source": [
    "da_empty = xr.DataArray(np_empty, coords=[isimip_lats, isimip_lons], dims=['lats','lons'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "25a44336-b43d-4f2f-9fda-f034c7d4fff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxas = [\"Reptiles\"]\n",
    "models =[\"GAM\",\"GBM\"] \n",
    "time=[35]\n",
    "years= ['1845', '1990', '1995', '2009', '2010', '2020', '2026', '2032', '2048', '2050','2052', '2056', '2080', '2100', '2150', '2200', '2250']\n",
    "year_indices = {35: 9, 65: 12, 85: 13}\n",
    "selected_year = years[year_indices[time[0]]]\n",
    "if time[0] == 35 or time[0] == 65:\n",
    "    model_names = ['GFDL-ESM2M', 'IPSL-CM5A-LR', 'HadGEM2-ES', 'MIROC5']\n",
    "    bioscen_model_names = ['GFDL.ESM2M', 'IPSL.CM5A-LR', 'HadGEM2.ES', 'MIROC5']\n",
    "elif time[0] == 85:\n",
    "    model_names = ['IPSL-CM5A-LR', 'HadGEM2-ES', 'MIROC5']\n",
    "    bioscen_model_names = ['IPSL.CM5A-LR', 'HadGEM2.ES', 'MIROC5']\n",
    "    scenarios = [\"rcp26\",\"rcp60\"]\n",
    "ssprcps_shorts = [\"ssp126\",\"ssp460\"]\n",
    "ssprcps_longs = [\"ssp1_rcp2.6\",\"ssp4_rcp6.0\"]\n",
    "combinations = list(itertools.product(models, model_names))\n",
    "\n",
    "for taxa in taxas:# Get all possible combinations of models and model_names    \n",
    "        for model in models :\n",
    "            for model_name in model_names:\n",
    "                for bioscen_model_name in bioscen_model_names:\n",
    "                    for scenario in scenarios:\n",
    "                        for k, ssprcp_long in enumerate(ssprcps_longs):\n",
    "                            for l, ssprcp_short in enumerate(ssprcps_shorts):\n",
    "\n",
    "\n",
    "                                convcodes = pd.read_csv(\"/storage/homefs/ch21o450/scripts/BioScenComb/data/IUCN_LUH_converion_table_Carlson.csv\")\n",
    "                                dir_habclass = \"/storage/homefs/ch21o450/IUCN/Habitat_Classifications/new/\" \n",
    "\n",
    "                                dir_species = \"/storage/workspaces/wa_climate/climate_trt/data/BioScen15/individual_projections/\" + taxa+ \"_\" + model +\"_results_climate/\"\n",
    "                                available_file = os.listdir(dir_species)\n",
    "                                available_names = [x.split(\".csv\")[0] for x in available_file]\n",
    "\n",
    "                                formatted_names = []\n",
    "\n",
    "                                for species_name in available_names:\n",
    "                                    split_species_name = species_name.split(\"_\")[:2]\n",
    "                                    formatted_species_name = \" \".join(split_species_name)\n",
    "                                    formatted_names.append(formatted_species_name)\n",
    "\n",
    "                                results = []\n",
    "                                for i, species_name in enumerate(formatted_names[:2]):\n",
    "                                    formatted_species_name = species_name.replace(\" \", \"_\")\n",
    "\n",
    "                                    for file_name in available_file:\n",
    "                                        if formatted_species_name in file_name and model + '_dispersal.csv.xz' in file_name:\n",
    "                                            species_file = file_name\n",
    "                                            species_file2 = [x.split(\".csv\")[0] for x in species_file] \n",
    "                                            break\n",
    "                                    else:\n",
    "                                        bioscen_species = None\n",
    "                                        continue\n",
    "\n",
    "                                    bioscen_species = pd.read_csv(dir_species + file_name)\n",
    "\n",
    "                                    available_files_iucn = formatted_species_name + \".csv\"\n",
    "                                    if available_files_iucn in os.listdir(dir_habclass):\n",
    "                                        IUCN = pd.read_csv(dir_habclass + available_files_iucn)\n",
    "                                    else:\n",
    "                                        continue\n",
    "\n",
    "                                    lon = bioscen_species[\"x\"]\n",
    "                                    lat = bioscen_species[\"y\"]\n",
    "                                    z = bioscen_species[bioscen_model_name + '_' + scenario + '_' + selected_year]\n",
    "\n",
    "                                    df = pd.DataFrame({\"lon\": lon, \"lat\": lat, \"vals\": z})\n",
    "                                    df = df.fillna(0)\n",
    "                                    convcodes_renamed = convcodes.rename(columns={'IUCN_hab':'result.code'})\n",
    "                                    Habitats = IUCN.merge(convcodes_renamed, left_on='result.code', right_on='result.code')\n",
    "\n",
    "                                    keys = ['LUH1', 'LUH2', 'LUH3', 'LUH4', 'LUH5', 'LUH6', 'LUH7', 'LUH8','LUH9','LUH10', 'LUH11', 'LUH12']\n",
    "                                    split_cols = Habitats['LUH'].str.split('.', expand=True)\n",
    "                                    for i, key in enumerate(keys):\n",
    "                                        if i < len(split_cols.columns):\n",
    "                                            Habitats[key] = split_cols[i]\n",
    "                                        else:\n",
    "                                            Habitats[key] = pd.Series(dtype='float64')\n",
    "                                    if len(Habitats.columns) > len(keys) + 1:\n",
    "                                        num_missing_cols = len(Habitats.columns) - len(keys) - 1\n",
    "                                        Habitats = Habitats.reindex(columns=list(Habitats.columns) + ['LUH{}'.format(i) for i in range(13, 13 + num_missing_cols)], fill_value=np.nan)\n",
    "                                        Habitats.drop('LUH', axis=1, inplace=True)\n",
    "                                    Habitats_suitable = Habitats[Habitats['result.suitability'] == 'Suitable'].copy()\n",
    "                                    if k == 0 and l == 0:\n",
    "                                        LandUseList = \"/storage/workspaces/wa_climate/climate_trt/data/LUH2/\" + ssprcps_longs[k] + \"/multiple-states_input4MIPs_landState_ScenarioMIP_UofMD-IMAGE-\" + ssprcps_shorts[l] + \"-2-1-f_gn_2015-2100.nc\"\n",
    "                                    elif k == 1 and l == 1:\n",
    "                                        LandUseList = \"/storage/workspaces/wa_climate/climate_trt/data/LUH2/\" + ssprcps_longs[k] + \"/multiple-states_input4MIPs_landState_ScenarioMIP_UofMD-GCAM-\" + ssprcps_shorts[l] + \"-2-1-f_gn_2015-2100.nc\"\n",
    "\n",
    "\n",
    "                                    isimip = xr.open_dataarray(\"/storage/workspaces/wa_climate/climate_trt/data/ISIMIP/ISIMIP3b/InputData/GCM/global/miroc6_r1i1p1f1_w5e5_ssp585_tasmin_global_daily_2071_2080.nc\")\n",
    "\n",
    "\n",
    "                                    ncfname = LandUseList\n",
    "                                    da_landuse =  xarray.open_dataset(ncfname, decode_times=False)\n",
    "                                    da_landuse = da_landuse.isel(time=time)\n",
    "\n",
    "                                    #prifdf_bin = xr.where(prifdf > 0, 1, 0)\n",
    "                                    df_sdm =df\n",
    "                                    da_landuse = da_landuse.coarsen(lon=2).mean().coarsen(lat=2).mean()\n",
    "\n",
    "                                    #build an empty np.array \n",
    "                                    np_empty = np.zeros_like(da_landuse['primf'].values, dtype=float)\n",
    "\n",
    "                                    isimip_lats = isimip['lat'].values\n",
    "                                    isimip_lons = isimip['lon'].values\n",
    " \n",
    "                                    da_empty = xr.DataArray(np_empty, coords=[ isimip_lats, isimip_lons], dims=['lats','lons'])\n",
    "                                    da_landclim = da_empty.assign_attrs(da_landuse)\n",
    "\n",
    "                                    keys = [\"primn\" if row[f\"LUH{i}\"] == \"primn\" else row[f\"LUH{i}\"] for _, row in Habitats_suitable.iterrows() for i in range(1, 5) if pd.notna(row[f\"LUH{i}\"])]\n",
    "                                    keys = list(set(keys))\n",
    "\n",
    "                                    # Compute the product with the \"newvalue\" column and assign it to a new column in the merged DataFrame\n",
    "                                    for code in keys: \n",
    "                                        # Compute the product with the \"newvalue\" column and assign it to a new column in the merged DataFrame\n",
    "                                        latitudes = df_sdm['lat'].unique()\n",
    "                                        longitudes = df_sdm['lon'].unique()\n",
    "\n",
    "                                        lats_sorted = np.sort(latitudes)\n",
    "                                        lons_sorted = np.sort(longitudes)\n",
    "\n",
    "                                        newvalue_array = np.zeros((len(lats_sorted), len(lons_sorted)))\n",
    "                                        for i, lat in enumerate(lats_sorted):\n",
    "                                            for j, lon in enumerate(lons_sorted):\n",
    "                                                selection = df_sdm[(df_sdm['lat'] == lat) & (df_sdm['lon'] == lon)]\n",
    "                                                if not selection.empty:\n",
    "                                                    newvalue_array[i, j] = selection['vals'].values[0]\n",
    "\n",
    "                                        da = xr.DataArray(newvalue_array, coords=[lats_sorted, lons_sorted], dims=['lat', 'lon'])\n",
    "                                        # Interpolate the values of newvalue to the dimensions of A\n",
    "                                        interpolated_values = da.interp(lat=isimip['lat'].values, lon=isimip['lon'].values)\n",
    "\n",
    "                                        # Add the interpolated values to the A DataArray\n",
    "                                        da_landuse['newvalue'] = interpolated_values\n",
    "                                        da_landuse['newvalue'] = interpolated_values.fillna(0)\n",
    "\n",
    "                                        # Compute the product with the LUH code and the \"newvalue\" column, and assign it to a new column in the merged DataFrame\n",
    "                                        np_empty = np.zeros_like(da_landuse[code].values, dtype=float)\n",
    "                                        da_landuse[f\"{code}_bin\"] = da_landuse[code] * da_landuse[\"newvalue\"]\n",
    "\n",
    "                                        # Select the DataArrays ending in \"_bin\"\n",
    "                                        bin_arrays = [da_landuse[var] for var in da_landuse.data_vars if var.endswith(\"_bin\")]\n",
    "\n",
    "                                        # Multiply all the arrays together\n",
    "                                        sum_bin = reduce(lambda x, y: x + y, bin_arrays)\n",
    "                                        # Assign the \"product_bin\" attribute to the da_landuse DataArray\n",
    "                                        da_landuse[\"sum_bin\"] = sum_bin\n",
    "                                        difference = da_landuse[\"sum_bin\"] - da_landuse[\"newvalue\"]\n",
    "                                        da_landuse[\"difference_filter\"] = difference\n",
    "\n",
    "                                        da_landclim = da_landclim.assign_attrs(da_landuse)\n",
    "\n",
    "                                        da_landuse.to_netcdf(\"/storage/homefs/ch21o450/scripts/BioScenComb/data/LandClim_Output/\" + model+ \"/\" + taxa + \"/\" + model_name + \"/\" + scenario + \"/\" + formatted_species_name + str(time)+ \".nc\")\n",
    "\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "80cb4bd4-59d0-49bb-90f1-0f06b2fce612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pletholax_gracilis.csv'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_files_iucn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "14507953-3aba-403b-8e8e-1f49e59360fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_files_iucn = formatted_species_name + \".csv\"\n",
    "if available_files_iucn in os.listdir(dir_habclass):\n",
    "    IUCN = pd.read_csv(dir_habclass + available_files_iucn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "60ac4f5d-2410-4775-9bd6-26b0c6d38424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>region_identifier</th>\n",
       "      <th>result.code</th>\n",
       "      <th>result.habitat</th>\n",
       "      <th>result.suitability</th>\n",
       "      <th>result.season</th>\n",
       "      <th>result.majorimportance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Sorex camtschatica</td>\n",
       "      <td>global</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Shrubland - Temperate</td>\n",
       "      <td>Suitable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                name region_identifier  result.code  \\\n",
       "0           1  Sorex camtschatica            global          3.4   \n",
       "\n",
       "          result.habitat result.suitability  result.season  \\\n",
       "0  Shrubland - Temperate           Suitable            NaN   \n",
       "\n",
       "   result.majorimportance  \n",
       "0                     NaN  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IUCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5b55044-9782-405d-9bac-4d75a0c91a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_landclim(taxas, models, model_names, bioscen_model_names, scenarios, ssprcps_longs, ssprcps_shorts, time=time):\n",
    "    for taxa in taxas:# Get all possible combinations of models and model_names    \n",
    "        for model in models :\n",
    "            for model_name in model_names:\n",
    "                for bioscen_model_name in bioscen_model_names:\n",
    "                    for scenario in scenarios:\n",
    "                        for k, ssprcp_long in enumerate(ssprcps_longs):\n",
    "                            for l, ssprcp_short in enumerate(ssprcps_shorts):\n",
    "\n",
    "\n",
    "                                convcodes = pd.read_csv(\"/storage/homefs/ch21o450/scripts/BioScenComb/data/IUCN_LUH_converion_table_Carlson.csv\")\n",
    "                                dir_habclass = \"/storage/homefs/ch21o450/IUCN/Habitat_Classifications/new/\" \n",
    "\n",
    "                                dir_species = \"/storage/workspaces/wa_climate/climate_trt/data/BioScen15/individual_projections/Mammals_\" + model +\"_results_climate/\"\n",
    "                                available_file = os.listdir(dir_species)\n",
    "                                available_names = [x.split(\".csv\")[0] for x in available_file]\n",
    "\n",
    "                                formatted_names = []\n",
    "\n",
    "                                for species_name in available_names:\n",
    "                                    split_species_name = species_name.split(\"_\")[:2]\n",
    "                                    formatted_species_name = \" \".join(split_species_name)\n",
    "                                    formatted_names.append(formatted_species_name)\n",
    "\n",
    "                                results = []\n",
    "                                for i, species_name in enumerate(formatted_names[:2]):\n",
    "                                    formatted_species_name = species_name.replace(\" \", \"_\")\n",
    "\n",
    "                                    for file_name in available_file:\n",
    "                                        if formatted_species_name in file_name and model + '_dispersal.csv.xz' in file_name:\n",
    "                                            species_file = file_name\n",
    "                                            species_file2 = [x.split(\".csv\")[0] for x in species_file] \n",
    "                                            break\n",
    "                                    else:\n",
    "                                        bioscen_species = None\n",
    "                                        continue\n",
    "\n",
    "                                    bioscen_species = pd.read_csv(dir_species + file_name)\n",
    "\n",
    "                                    available_files_iucn = formatted_species_name + \".csv\"\n",
    "                                    if available_files_iucn in os.listdir(dir_habclass):\n",
    "                                        IUCN = pd.read_csv(dir_habclass + available_files_iucn)\n",
    "                                    else:\n",
    "                                        continue\n",
    "\n",
    "                                    lon = bioscen_species[\"x\"]\n",
    "                                    lat = bioscen_species[\"y\"]\n",
    "                                    z = bioscen_species[bioscen_model_name + '_' + scenario + '_' + selected_year]\n",
    "\n",
    "                                    df = pd.DataFrame({\"lon\": lon, \"lat\": lat, \"vals\": z})\n",
    "                                    df = df.fillna(0)\n",
    "                                    convcodes_renamed = convcodes.rename(columns={'IUCN_hab':'result.code'})\n",
    "                                    Habitats = IUCN.merge(convcodes_renamed, left_on='result.code', right_on='result.code')\n",
    "\n",
    "                                    keys = ['LUH1', 'LUH2', 'LUH3', 'LUH4', 'LUH5', 'LUH6', 'LUH7', 'LUH8','LUH9','LUH10', 'LUH11', 'LUH12']\n",
    "                                    split_cols = Habitats['LUH'].str.split('.', expand=True)\n",
    "                                    for i, key in enumerate(keys):\n",
    "                                        if i < len(split_cols.columns):\n",
    "                                            Habitats[key] = split_cols[i]\n",
    "                                        else:\n",
    "                                            Habitats[key] = pd.Series(dtype='float64')\n",
    "                                    if len(Habitats.columns) > len(keys) + 1:\n",
    "                                        num_missing_cols = len(Habitats.columns) - len(keys) - 1\n",
    "                                        Habitats = Habitats.reindex(columns=list(Habitats.columns) + ['LUH{}'.format(i) for i in range(13, 13 + num_missing_cols)], fill_value=np.nan)\n",
    "                                        Habitats.drop('LUH', axis=1, inplace=True)\n",
    "                                    Habitats_suitable = Habitats[Habitats['result.suitability'] == 'Suitable'].copy()\n",
    "                                    if k == 0 and l == 0:\n",
    "                                        LandUseList = \"/storage/workspaces/wa_climate/climate_trt/data/LUH2/\" + ssprcps_longs[k] + \"/multiple-states_input4MIPs_landState_ScenarioMIP_UofMD-IMAGE-\" + ssprcps_shorts[l] + \"-2-1-f_gn_2015-2100.nc\"\n",
    "                                    elif k == 1 and l == 1:\n",
    "                                        LandUseList = \"/storage/workspaces/wa_climate/climate_trt/data/LUH2/\" + ssprcps_longs[k] + \"/multiple-states_input4MIPs_landState_ScenarioMIP_UofMD-GCAM-\" + ssprcps_shorts[l] + \"-2-1-f_gn_2015-2100.nc\"\n",
    "\n",
    "\n",
    "                                    isimip = xr.open_dataarray(\"/storage/workspaces/wa_climate/climate_trt/data/ISIMIP/ISIMIP3b/InputData/GCM/global/miroc6_r1i1p1f1_w5e5_ssp585_tasmin_global_daily_2071_2080.nc\")\n",
    "\n",
    "\n",
    "                                    ncfname = LandUseList\n",
    "                                    da_landuse =  xarray.open_dataset(ncfname, decode_times=False)\n",
    "                                    da_landuse = da_landuse.isel(time=time)\n",
    "\n",
    "                                    #prifdf_bin = xr.where(prifdf > 0, 1, 0)\n",
    "                                    df_sdm =df\n",
    "                                    da_landuse = da_landuse.coarsen(lon=2).mean().coarsen(lat=2).mean()\n",
    "\n",
    "                                    #build an empty np.array \n",
    "                                    np_empty = np.zeros_like(da_landuse['primf'].values, dtype=float)\n",
    "\n",
    "                                    isimip_lats = isimip['lat'].values\n",
    "                                    isimip_lons = isimip['lon'].values\n",
    "\n",
    "                                    da_empty = xr.DataArray(np_empty, coords=[isimip_lats, isimip_lons], dims=['lats','lons'])\n",
    "                                    da_landclim = da_empty.assign_attrs(da_landuse)\n",
    "\n",
    "                                    keys = [\"primn\" if row[f\"LUH{i}\"] == \"primn\" else row[f\"LUH{i}\"] for _, row in Habitats_suitable.iterrows() for i in range(1, 5) if pd.notna(row[f\"LUH{i}\"])]\n",
    "                                    keys = list(set(keys))\n",
    "\n",
    "                                    # Compute the product with the \"newvalue\" column and assign it to a new column in the merged DataFrame\n",
    "                                    for code in keys: \n",
    "                                        # Compute the product with the \"newvalue\" column and assign it to a new column in the merged DataFrame\n",
    "                                        latitudes = df_sdm['lat'].unique()\n",
    "                                        longitudes = df_sdm['lon'].unique()\n",
    "\n",
    "                                        lats_sorted = np.sort(latitudes)\n",
    "                                        lons_sorted = np.sort(longitudes)\n",
    "\n",
    "                                        newvalue_array = np.zeros((len(lats_sorted), len(lons_sorted)))\n",
    "                                        for i, lat in enumerate(lats_sorted):\n",
    "                                            for j, lon in enumerate(lons_sorted):\n",
    "                                                selection = df_sdm[(df_sdm['lat'] == lat) & (df_sdm['lon'] == lon)]\n",
    "                                                if not selection.empty:\n",
    "                                                    newvalue_array[i, j] = selection['vals'].values[0]\n",
    "\n",
    "                                        da = xr.DataArray(newvalue_array, coords=[lats_sorted, lons_sorted], dims=['lat', 'lon'])\n",
    "                                        # Interpolate the values of newvalue to the dimensions of A\n",
    "                                        interpolated_values = da.interp(lat=isimip['lat'].values, lon=isimip['lon'].values)\n",
    "\n",
    "                                        # Add the interpolated values to the A DataArray\n",
    "                                        da_landuse['newvalue'] = interpolated_values\n",
    "                                        da_landuse['newvalue'] = interpolated_values.fillna(0)\n",
    "\n",
    "                                        # Compute the product with the LUH code and the \"newvalue\" column, and assign it to a new column in the merged DataFrame\n",
    "                                        np_empty = np.zeros_like(da_landuse[code].values, dtype=float)\n",
    "                                        da_landuse[f\"{code}_bin\"] = da_landuse[code] * da_landuse[\"newvalue\"]\n",
    "\n",
    "                                        # Select the DataArrays ending in \"_bin\"\n",
    "                                        bin_arrays = [da_landuse[var] for var in da_landuse.data_vars if var.endswith(\"_bin\")]\n",
    "\n",
    "                                        # Multiply all the arrays together\n",
    "                                        sum_bin = reduce(lambda x, y: x + y, bin_arrays)\n",
    "                                        # Assign the \"product_bin\" attribute to the da_landuse DataArray\n",
    "                                        da_landuse[\"sum_bin\"] = sum_bin\n",
    "                                        difference = da_landuse[\"sum_bin\"] - da_landuse[\"newvalue\"]\n",
    "                                        da_landuse[\"difference_filter\"] = difference\n",
    "\n",
    "                                        da_landclim = da_landclim.assign_attrs(da_landuse)\n",
    "\n",
    "                                        da_landuse.to_netcdf(\"/storage/homefs/ch21o450/scripts/BioScenComb/data/LandClim_Output/\" + model+ \"/\" + taxa + \"/\" + model_name + \"/\" + scenario + \"/\" + formatted_species_name + str(time)+ \".nc\")\n",
    "\n",
    "                                        #da_landclim.to_netcdf(\"/storage/homefs/ch21o450/scripts/BioScenComb/data/LandClim_Output/\" + taxa[0] + \"_\" + model[0] + \"/\" + model_names[0] + \"/\" + scenarios[0] + \"/\" + formatted_species_name +\".nc\")       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
